<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Joey's Blog]]></title>
  <link href="http://xcaptain.github.io/atom.xml" rel="self"/>
  <link href="http://xcaptain.github.io/"/>
  <updated>2015-03-15T01:26:39+08:00</updated>
  <id>http://xcaptain.github.io/</id>
  <author>
    <name><![CDATA[joey]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Use-orgmode]]></title>
    <link href="http://xcaptain.github.io/blog/2015/03/15/use-orgmode/"/>
    <updated>2015-03-15T00:58:56+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/03/15/use-orgmode</id>
    <content type="html"><![CDATA[<p>最近看书学习感觉非常没有劲，究其原因感觉是缺少一个做笔记的工具，原来那支跟随我4年的钢笔放家里没有带过来，
京东上预订的lamy也还没有到货，看书不动笔我是什么都记不住的，所以感觉学习效率低了很多。印象笔记确实不错，
配合浏览器的markdown-here扩展就能支持markdown语法了，但是缺少一个所见即所得的笔记客户端，用markdown写完
之后转换为html还是感觉不够方便，并且总是要有网才能看到和编辑笔记很不方便。gnome自带的tomboy我也尝试了，
这东西更加不好用，连markdown都不支持怎么能拿来记笔记。</p>

<p>今天反正周六闲着没事就拿起了orgmode的<a href="http://orgmode.org/org.html">手册</a> 来看，看了几页竟然发现org转md是这么方便，果断以后就用emacs来
记笔记了，又学会一个新技能。</p>

<ul>
<li>下面就来讲讲org做笔记的基本用法吧:

<ol>
<li>使用星号来表明段落的层级，和md的使用#差不多的概念</li>
<li>支持有序列表，无序列表，语法和md类似，org或自动缩进对其每个列表项，如果发现不匹配了那就肯定某个地方缩进出问题了</li>
<li>插入链接\[[链接]\[名字]] 这样就能插入一条链接了</li>
<li>用\\来断行，这样就不必要把一段话写在一行了</li>
<li>C-c C-e m m 来导出markdown文件</li>
</ol>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Emacs自定义grep-find的模板]]></title>
    <link href="http://xcaptain.github.io/blog/2015/03/07/emacs-grep-find/"/>
    <updated>2015-03-07T22:40:19+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/03/07/emacs-grep-find</id>
    <content type="html"><![CDATA[<p>被emacs的搜索功能纠结好久了，今天下定决心来解决一下。以前执行<code>grep-find</code>命令的时候查找的模板都是<code>find . -type f -exec grep -nH -e {} +</code>，但是这条命令在fish下没法用，找了一下发现在<a href="https://github.com/fish-shell/fish-shell/issues/95">这个issue</a>里面作者提到了为什么fish里面没法用find，因为在fish里面<code>{}</code>是有意义的，所以就会提示exec缺少参数，所以如果写成<code>find . -type f -exec grep -nH -e '{}' +</code>就可以了，接下来的任务就是修改emacs的配置，把默认的<code>grep-find</code>的行为改掉。</p>

<p>因为查找功能是emacs默认就有的，所以我直接就去源代码目录找了，在<code>/usr/share/emacs/24.4/</code>下执行<code>grep 'grep-find' -R *</code>，然后在<code>lisp/ldefs-boot.el</code>和<code>lisp/loaddefs.el</code>找到了相关的代码，然后试着修改第12669行，这行看起来像是相关的代码，结果改完了半天不生效，无奈之下去<a href="http://stackoverflow.com/questions/28915372/change-the-default-find-grep-command-in-emacs/">stackoverflow</a>提问，这个网站效率真的不是一般的高，很快就拿到答案了，有人说我找到的代码只不过是docstring而已，要修改的话得改<code>grep-find-template</code>,通过<code>C-h v</code>查看了一下这个变量的值，默认的是<code>"find . &lt;X&gt; -type f &lt;F&gt; -exec grep &lt;C&gt; -nH -e &lt;R&gt; {} +"</code>，修改它就行了，编辑<code>~/.emacs.d/personal/custom.el</code>，在最底下加上<code>(setq grep-find-template "find . &lt;X&gt; -type f &lt;F&gt; -exec grep &lt;C&gt; -nH -e &lt;R&gt; \'{}\' +")</code>，然后<code>eval-buffer</code>，问题完美解决，不得不说emacs真是灵活，不用改源代码就能实现自定义功能。</p>

<p>后面又修改了<code>find-grep-dired</code>的模板，好像这条命令没有模板，所以我直接改的代码，<code>/usr/share/emacs/24.4/lisp/find-dired.el.gz</code>编辑第278行，把{}转义了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[学习emacs-eww]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/28/emacs-eww/"/>
    <updated>2015-01-28T22:50:06+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/28/emacs-eww</id>
    <content type="html"><![CDATA[<p>最近一段时间比较无聊，<a href="http://www.iyue.club">http://www.iyue.club</a>一直没有去维护了，目标不明确，不知道奋斗目标。
而且工作的事比较无聊，不断的重构原有的代码，想着怎么尽量把代码写短写优化，接触的新东西也不多，这么久没有学习新东西都让我感到深深的危机感了。</p>

<p>目前的计划还是慢慢来学习ruby on rails，所以空闲时间就做点有意思的事情了。现在来记录一下eww的用法，以后便于查阅，熟能生巧。eww的文档可以通过emacs自身来查看，现在就来总结一下emacs文档里对eww的介绍，我都是通过<code>C-h r</code>来打开emacs自带的info然后查找到eww的章节然后开始看的。</p>

<p>基本操作：</p>

<ol>
<li><code>M-x eww RET</code>输入url或者关键字，就可以打开url或者用内建的dockdockgo来搜索。</li>
<li><code>l</code> 回到上一个页面，回退。</li>
<li><code>r</code> 回到下一个页面，回进。</li>
<li><code>d</code> 下载当前链接，默认保存在<code>~/Downloads</code>，这个快捷键对于下载图片很方便。</li>
<li><code>g</code> 刷新当前页面。</li>
<li><code>w</code> 复制当前url到剪切板。</li>
<li><code>H</code> 查看历史记录。</li>
<li><code>b</code> 添加书签。</li>
<li><code>B</code> 查看书签。</li>
<li><code>&amp;</code> 调用外部浏览器打开当前url。</li>
<li><code>v</code> 查看当前页面源码，如果安装了html-mode就会用html-mode来渲染。</li>
<li><code>C</code> 查看所有存在的cookie</li>
</ol>


<p>上面这些东西都可以查看文档得到，比较没有营养，还是学习新东西有意思。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用btsync]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/20/use-btsync/"/>
    <updated>2015-01-20T18:18:25+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/20/use-btsync</id>
    <content type="html"><![CDATA[<p><meta charset="UTF-8"/>
昨天从<a href="http://program-think.blogspot.com/">编程随想</a>的博客上知道了<a href="https://www.getsync.com/">btsync</a>这个东西，用来p2p分享文件很是方便，所以我也尝试了一下，配置很简单，我在自己的笔记本和公司电脑都装好了，这样上班的时候2台电脑同步文件就方便了。</p>

<p>但是遇到了一个有点麻烦的问题，在最初我能够脸上p2p网络，并且找到了供源的机器，但是就是没法和他们同步，总是提示和另一方时间偏差太大无法同步，搜了一下发现是系统时间设置的问题，通过<a href="https://wiki.archlinux.org/index.php/Time">wiki</a>又好好了解了一下linux的时间机制。</p>

<p>linux上的时间包括2种，一是硬件时间，另一个是系统时间。</p>

<ol>
<li><p>硬件时间：(Real Time Clock, RTC)是由机器硬件记录的时间，根据<a href="http://www.tldp.org/LDP/sag/html/hw-sw-clocks.html">tldp</a>的说法，个人电脑都内建了一块独立的电池，来给一个时钟供电，这个时钟可以通过BIOS来设置，或者开机之后通过操作系统来设置。</p></li>
<li><p>系统时间:(software clock)，这个时间是由linux内核来设置的。在系统中存放着一个叫做<code>/etc/adjtime</code>的配置文件，我本机这个文件是7月份创建的，也就是我上次重装系统的时间，是linux的初始系统时间，之后linux估计用了某种还不清楚的手段，每次开机都会更新最新的系统时间。</p></li>
</ol>


<p>我的问题就是系统时间和硬件时间不一致，估计是因为双系统和windows共存导致的，解决方法就是通过执行<code>sudo hwclock --systz</code>来把系统时间和硬件时间都和本地时区的时间对齐。时区配置文件是<code>/etc/localtime</code>这个文件可以通过<code>timedatectl</code>命令来设置，也可以手动建立到<code>/usr/share/zoneinfo/Asia/Hong_Kong</code>的软链接，或者是直接复制<code>/usr/share/zoneinfo/Hong_Kong</code>到<code>/etc/localtime</code>来设置。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python2编码问题]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/13/python-encoding/"/>
    <updated>2015-01-13T08:06:21+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/13/python-encoding</id>
    <content type="html"><![CDATA[<p>这篇文章是要记录今天写一个采集是遇到的编码问题的，但是因为在写博客时遇到了一些问题，所以也就顺便记录一下。</p>

<p>在执行rake new_post的时候，突然提示</p>

<pre>
rake aborted!
LoadError: cannot load such file -- bundler/setup
/home/joey/octopress/Rakefile:2:in `<top (required)>'
(See full trace by running task with --trace)
</pre>


<p>突然感觉很奇怪，前几天更新博客的时候都没有遇到这种情况，后来执行<code>rake --trace</code>的时候发现</p>

<pre>
/usr/lib/ruby/2.2.0/rubygems/core_ext/kernel_require.rb:54:in `require'
/usr/lib/ruby/2.2.0/rubygems/core_ext/kernel_require.rb:54:in `require'
/home/joey/octopress/Rakefile:2:in `<top (required)>'
/usr/lib/ruby/2.2.0/rake/rake_module.rb:28:in `load'
/usr/lib/ruby/2.2.0/rake/rake_module.rb:28:in `load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:689:in `raw_load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:94:in `block in load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:176:in `standard_exception_handling'
/usr/lib/ruby/2.2.0/rake/application.rb:93:in `load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:77:in `block in run'
/usr/lib/ruby/2.2.0/rake/application.rb:176:in `standard_exception_handling'
/usr/lib/ruby/2.2.0/rake/application.rb:75:in `run'
/usr/bin/rake:33:in `<main>'
</pre>


<p>原来是系统ruby的版本更新到2.2了，以前是2.1的，octopress用的是2.1的gem，也许是和2.2的ruby不兼容吧，所以要重装2.2的gem套系，执行<code>proxychains gem install bundle</code>，有经验了必须要通过代理才能访问rubygem网站，下载完之后需要把<code>/home/joey/.gem/ruby/2.2.0/bin</code> 添加到环境变量中，因为我用的是fish，所以编辑<code>~/.config/fish/config.fish</code>就行了。然后用bundle安装完必要的依赖<code>proxychains bundle install</code>，下载一大堆gem，最后发现系统用的rake已经是10.4.2版的了，而配置文件中需要的还是10.4.0,手动编辑一下<code>Gemfile.lock</code>，把版本号改过来就行了，后来又重装了一下<code>safe_yaml</code>和<code>liquid</code>，把对应的版本号也都改过来了，一个小版本升级搞得这么麻烦，真是郁闷。</p>

<p>接下来就是说说今天写代码遇到的问题了。</p>

<p>需求很简单（话说写采集需求都很明确），这回需要的是采集明星的信息，第一个方案用的是采集baidu整理的明星信息，过程很简单，写了一个简单的脚本采了900条数据，但是后来发现图片做了防盗链，采集过来的图片不是图片的绝对路径，而是通过一台服务器生成的图片，也许是做了cookie的限制或者是做了ip的限制，导致每次刷新页面的时候都会返回一个403错误，链接在<a href="http://www.baidu.com/s?wd=%E6%98%8E%E6%98%9F%E5%A4%A7%E5%85%A8&amp;rsv_spt=1&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=4&amp;rsv_sug4=83&amp;rsv_sug1=3&amp;rsv_pq=d5fdf7cd00002ac7&amp;rsv_t=975c0jUWTeYgIUYA%2FfdqSJ75f%2BipUP9QR9v8Qgqb2jzy3rnHgTU3k4rBD%2B5moP73i00p&amp;rsv_sug2=0&amp;inputT=5564">这里</a>，以后有时间也许会去看看这个防盗链的实现，但是现在我可懒得花时间去研究怎么破解这个限制，那就换别的站采集吧。</p>

<p>和产品沟通了一下，他也觉得如果死扣baidu是不明智的选择，后来换成360整理的资源了，链接在<a href="http://www.haosou.com/s?ie=utf-8&amp;shb=1&amp;src=360sou_newhome&amp;q=%E6%98%8E%E6%98%9F%E5%A4%A7%E5%85%A8">这里</a>，数据也比较明确，分成3栏：领域，地域，性别，这个分类还是比较好的，以后我们拿来查询也方便。通过chrome开发工具，找到了js的接口，简单分析了一下就知道要获取那块数据，接下来就是敲代码了，最后的代码在<a href="https://gist.github.com/xcaptain/cbf9980f1b30b2467d8a">这里</a>，本来是打算试试octopress对于gist的支持的，但是因为gist在国内被墙了，会影响整篇文章的阅读，所以就换个链接在这里，有兴趣的朋友就去看看。</p>

<p>在写代码过程中遇到一个编码问题，困扰我很久，不过最终还是解决了。</p>

<p>在使用python2的时候，要自己手动设置编码，python默认的字符串编码是ascii，这就导致如果在python2程序中出现了中文都会提示一个语法错误，但是如果在python2文件中强制加上一句<code># -*- coding: utf-8 -*-</code> 这样python在执行程序的时候就知道使用utf-8来编码里面的字符串了。也许是我本地locale的设置，在打开python解释器的时候总是会自动帮我使用utf-8编码。
首先说说ascii编码，ascii只能编码代码点从0到127的字符，也就是英文字符，如果遇到代码点很高的字符，比如说中文，就没法争取的编码了，就会报错。下面来举几个例子：</p>

<pre><code class="python2">s1 = '你好，world' #这里如果指定了文件的编码为utf-8，会自动把这个字符串编码成utf-8
s1 =&gt; '\xe4\xbd\xa0\xe5\xa5\xbd\xef\xbc\x8cworld'
s2 = u'你好，world' #这里前面加了一个u来表明这个字符串是一个unicode字符串
s2 =&gt; u'\u4f60\u597d\uff0cworld'
u2 = s2.encode('utf-8')
u2 =&gt; '\xe4\xbd\xa0\xe5\xa5\xbd\xef\xbc\x8cworld'
</code></pre>

<p>字符串在内存中应该是用类似utf-8的形式存储的，这样比较节省内存空间，而且也不会出现太多的0导致字符串在大尾和小尾机器上的不兼容。所以对于一个python字符串的旅程可以大致归结为：</p>

<ol>
<li>在编辑器里写下<code>s1 = '你好，world'</code>然后保存为一个python文件的时候，编辑器会自动选择某种编码来保存这个文件，一般来说都是用的utf-8。</li>
<li>python把这个程序加载进解释器的时候，会根据文件头来判断使用什么编码来解码这个文件，也就是<code># -*-coding: utf-8 -*-</code>这行，如果没有这行就会用默认的<code>ascii</code>来解码。</li>
<li>这时候程序里的字符串都是utf8的。
写到这里突然发现昨晚的问题实在不算问题，看来之前是没有静下心来研究，写博客还是有好处的。</li>
</ol>


<p>接下来再看看python3,python3的默认编码是unicode，而实际存在内存中的就是字节码，bytecode。也就是说一个字符串只有2种状态，unicode和byte，这样就节省很多事情了，没有各种编码解码的麻烦。
<code>python3
s = '你好，world' #这是一个str类型的字符串
b1 = s.encode('utf-8') #这是把s编码为utf-8后的字节码
b2 = s.encode('gbk') #把s编码为gbk后的字节码
</code>
相对于2来说，3最大的进步就是不需要手动encode，decode，对于处理未知编码的文件最方便了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[玩弄git]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/06/play-with-git/"/>
    <updated>2015-01-06T06:54:11+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/06/play-with-git</id>
    <content type="html"><![CDATA[<p>经过元旦几天的努力，论坛正式上线了<a href="http://f.joxy.org">http://f.joxy.org</a>，目前仅仅是使用了<a href="https://github.com/discourse/discourse">discourse</a>的框架，自己还没有开始定制，总是需要一个熟悉的过程的，本地的开发环境因为邮件的问题，现在还没有好，挺郁闷的。</p>

<p>今晚就稍微熟悉了一下discourse的结构。</p>

<ol>
<li>我本地的开发环境，这个没什么多说的，就是用vagrant跑了一个虚拟机，上面运行着discourse需要的环境。</li>
<li>线上的环境是用docker运行的，这是官方推荐的安装方式，说实话最初我竟然没有明白discourse的架构。</li>
</ol>


<p>其实也是很简单的，在我的vps上跑着一个docker，docker类似于一个虚拟机，创建了一个容器，里面跑着discourse需要的环境。代码存放在<code>/var/www/discourse</code>下，但是因为是用官方的安装方法安装的，只能等官方的更新，如果我们要自定义怎么办呢？那就需要改git的配置了。</p>

<p>我在github上面fork了官方的仓库，把这个自己的仓库拷贝到本地，改了一些简单的文件，提交，这时候我去官方仓库看，发现他们竟然领先我好多个版本，那就 把他们的改动也拿过来吧，这里需要添加官方仓库的配置，使用<code>git remote add upstream git://github.com/discourse/discourse.git</code>，这时候会发现在<code>.git/config</code>里面多了一个remote的配置，如果需要把这个upstream的改动也合并到自己的仓库，就要<code>git fetch upstream</code>，等改动都更新下来了之后会存放在<code>.git</code>目录下，这时候代码还没有变化。如果执行<code>git pull upstream master</code>，就能把版本库中的版本检出到主分支了。然后执行<code>git push origin master</code>就能把本地的版本更新到github了。</p>

<p>我想把改动也更新到vps上，那就需要改vps上git仓库的配置了。</p>

<ol>
<li><p><code>cd /var/discourse/</code>
切换到docker配置所在的目录</p></li>
<li><p><code>./launcher ssh app</code>
因为我当初初始化配置的时候用的是app来作为container的名字，所以要加上app参数</p></li>
<li><p><code>cd /var/www/discourse/</code></p></li>
<li><p><code>git remote add develop git://github.com/xcaptain/discourse.git</code>
这样就把我的github仓库中的版本作为开发版加入到线上的配置了。</p></li>
<li><p><code>git pull develop master</code>
 就能把我的版本拿下来了，因为我的这个版本都会现在本地开发环境测试过之后再上，所以是很安全的</p></li>
</ol>


<p>这样应该也算是和一大伙志愿者协同开发吧，虽然我没有提交pull request，但是我一直在用别人的免费的代码，真是惭愧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[调试shadowsocks]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/04/debug-shadowsocks/"/>
    <updated>2015-01-04T07:16:58+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/04/debug-shadowsocks</id>
    <content type="html"><![CDATA[<p>昨天把在东京的虚拟机搬到加州去了，感觉这次搬家还是很值得的，传输稳定了很多，原来在东京的时候看个youtube经常卡，但是现在看youtube很流畅，不过每月多给2美元，让我帐号里的钱花得更快了。原来装的是freebsd10的系统，现在我把系统换成ubuntu14.04了，因为bsd的软件还是比较老的，而ubuntu就新多了，而且docker和container等都得在linux才能跑。</p>

<p>系统安装完之后肯定是要部署shadowsocks的，操作很简单就不多说了，一点问题都没有，但是今天早上起床开机就发现没法翻墙了，这时候问题就出现了，耽误我一整天时间。</p>

<p>笔记本没法翻墙是什么问题呢？试了一下手机，用fqrouter是没问题的，那就说明服务器端是没问题的，好吧，在客户端上找原因。</p>

<p>之前安装的客户端是nodejs版的，一直都这么用感觉没什么问题，现在我就打算换个客户端版本，试试python的。安装也很简单，但是就是上不了网，真是郁闷。没办法了，慢慢来调试找问题吧。我在服务器端和客户端都开启了-v参数，用来详细输出日志。</p>

<ol>
<li><p>用fqrouter访问的时候，服务器端输出：
 <pre>
 2015-01-03 08:48:07 INFO: accept a connection.
 2015-01-03 08:48:07 INFO: connect to: 106.162.216.94:443
 2015-01-03 08:48:07 INFO: asyncns resolved.
 2015-01-03 08:48:07 INFO: remote connected.
 </pre>
 看来这是正常连接，返回数据也正常。</p></li>
<li><p>本地用firefox访问google，服务器端输出：
 <pre>
 2015-01-03 08:49:56 INFO: accept a connection.
 2015-01-03 08:49:56 INFO: connect to: plus.google.com:443
 2015-01-03 08:50:16 INFO: asyncns resolved.
 2015-01-03 08:50:16 ERROR: getaddrinfo: Operation now in progress
 2015-01-03 08:50:16 INFO: current server connection: 2
 </pre>
 这就是失败的连接在服务器的日志了，只看到一行错误，搞不懂原因。</p></li>
<li><p>在服务器端执行<code>netstat -naltp | grep 8388</code>的输出：
 <pre>
 tcp        0      0 111.222.231.123:8388    0.0.0.0:*               LISTEN      1738/ss-server
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29403     ESTABLISHED 1738/ss-server
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29406     ESTABLISHED 1738/ss-server
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29402     TIME_WAIT   -
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29400     TIME_WAIT   -
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29401     TIME_WAIT   -
 </pre>
 本地可以连接服务器的端口，那为什么没有数据返回呢？</p></li>
<li><p>在本地执行<code>netstat -naltp | grep 1080</code>的输出：
 <pre>
 tcp        0      0 127.0.0.1:1080          0.0.0.0:*               LISTEN      732/python
 tcp        0      0 127.0.0.1:45312         127.0.0.1:1080          ESTABLISHED 744/firefox
 tcp        0      0 127.0.0.1:1080          127.0.0.1:45312         ESTABLISHED 732/python
 tcp        0      0 127.0.0.1:1080          127.0.0.1:45307         TIME_WAIT   -
 tcp        0      0 127.0.0.1:1080          127.0.0.1:45309         TIME_WAIT   -
 </pre>
 看来浏览器和本地端口之间也是通的。</p></li>
</ol>


<p>本地应用可以连接本地的端口，本地的端口可以连接服务器，为什么就是没有数据呢？不会调试web程序，不会抓包，这时候只能乱猜原因，一下午都没有想通问题，就在我想要发帖求助的时候，想了一下为什么用fqrouter的时候服务器端接收到的是一个ip，而本地客户端连接服务器的时候就是一个域名，也许dns出问题了，试了一下<code>ping www.google.com</code>，果然不通，问题找到了，虚拟机提供商这个机房的dns昨晚出问题了，导致解析失败，添加一个第三方的dns，问题解决。</p>

<p><code>vi /etc/resolvconf/resolv.conf.d/base</code>添加下面2行</p>

<pre>
nameserver 8.8.8.8
nameserver 8.8.4.4
</pre>


<p>然后执行<code>resolvconf -u</code>刷新dns，这样就能使用google的dns了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[部署邮件服务]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/03/deploy-email-service/"/>
    <updated>2015-01-03T08:43:43+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/03/deploy-email-service</id>
    <content type="html"><![CDATA[<p>今天打算研究一下搭建自己的mail server用来收发邮件，不过后来发现在自己服务器上部署邮件服务太麻烦了，没有那么高性能的服务器，而且额外开放的服务可能会被黑客利用，那么就采用第三方的邮件服务吧。</p>

<h4>首先确定一下发件服务。</h4>

<p>根据网上的推荐，我用的是<a href="https://mandrillapp.com/">mandril</a>，这家公司为免费帐号提供每月发12000封邮件，对于个人玩来说足够了。接下来就是注册帐号，注册完成之后会有一个向导引导着去配置发件服务。填好之后配置都会出现在<a href="https://mandrillapp.com/settings">这里</a>，这些配置包括发件服务器的域名，端口，smtp用户名，以及密码，密码是网站生成的，要好好保存。</p>

<h4>然后就是配置收件服务</h4>

<p>同样也是根据网上的推荐，收件服务用的是国内一家公司的，叫做<a href="https://www.zoho.com/">zoho</a>，这家公司为每个免费帐号提供一个代收域名，15个免费邮箱，每个免费邮箱提供5G存储空间，对于个人玩来说也是足够了的，因为可以把邮件下载到本地，然后删除服务器上的邮件存档，所以这5G的空间可以永远也用不完。好像这家公司就在中关村，真想去参观一下。用zoho的原因是它提供邮件代收服务，我有一个域名<code>joxy.org</code>，我想注册一些邮箱以<code>@joxy.org</code>结尾，zoho就提供这种功能。过程也是很简单，需要先去注册帐号，注册帐号的时候要验证你是否对这个域名有所有权，所以还需要去<a href="https://mya.godaddy.com/">godaddy</a>上面验证一下，我是通过cname的形式来验证的。注册完成之后还得配置一下godaddy，因为在注册域名的时候默认设置了2个收件商，现在我不想用那2个厂商的收件服务了，所以要改改dns设置，找到mx这条配置，删掉额外的2个厂商的配置，然后加上一条mx记录，Host是@,表示joxy.org自身，Points to填mx2.zohomail.com，剩下的随便填就行了。这样当有人往<code>user@joxy.org</code>发邮件的时候，发件服务器通过dns查询的时候就知道要发给zoho，zoho就可以帮忙代收。</p>

<h4>发件服务和收件服务都配置好了，接下来就是测试一下是否能收发邮件了。</h4>

<p>用thunderbird可以很方便的写邮件收邮件。把我刚刚创建的xiefei@joxy.org这个帐号创建了，手动配置好这个帐号发送邮件和接收邮件的设置，就可以开始测试了。在配置smtp发件的时候需要输入密码验证用户是否有权限来发邮件，所以一定要记得填smtp的密码。我测试了一下和我的gamil邮箱互发邮件，一点问题都没有，而且邮件也没有进入垃圾箱。这真是太好了，图形界面的客户端可以收发邮件，真想看看通过php,ruby脚本能不能发邮件。</p>

<p>以上的配置参考了youtube上的<a href="https://www.youtube.com/watch?v=ndIflJOGSww">一个视频</a>，真感谢作者分享这么好的东西，省去了我翻资料学习的过程。</p>

<p>刚刚测试discourse的时候已经把邮件功能加上了，可以发送，真是神奇啊。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决pacman依赖关系破裂问题]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/01/arch-pacman-broken/"/>
    <updated>2015-01-01T19:35:23+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/01/arch-pacman-broken</id>
    <content type="html"><![CDATA[<p>今天准备更新一下系统，执行<code>sudo pacman -Syu</code>的时候，竟然没法同步软件源了，报告说依赖错误。</p>

<pre>
packagekit: requires pacman<4.2.0
package-query: requires pacman<4.2.0
</pre>


<p>但是我查看了一下pacman的版本,<code>pacman --version</code>发现是4.1的满足需求啊，为什么会有这样的提示呢？我想用<code>sudo pacman -S pacman</code>重装pacman也不行，真是费解，这么重要的软件可千万不能出错啊。后来上网搜了一下，发现有人也遇到这种情况，都是直接<code>sudo pacman -R packagekit python-packagekit yaourt package-query</code>，然后再<code>sudo pacman-db-upgrade</code>升级一下数据库，然后再<code>sudo pacman -Syu</code>，ok问题解决。</p>

<p>还有一点是关于virtualbox的，今天我又用了一下vagrant，发现每次<code>vagrant up</code>都会提示：</p>

<pre>
VirtualBox is complaining that the kernel module is not loaded. Please
run `VBoxManage --version` or open the VirtualBox GUI to see the error
message which should contain instructions on how to fix this error.
</pre>


<p>用最简单的方法<code>sudo modprobe vboxdrv</code>然后<code>lsmod | grep vbox</code>发现加载进了</p>

<pre>
vboxdrv               348377  3 vboxnetadp,vboxnetflt,vboxpci`
</pre>


<p>但是这时候还是会报错说找不到网卡驱动，后来我执行<code>sudo vboxreload</code>显示：</p>

<pre>
vboxpci                23139  0
vboxnetflt             27412  0
vboxnetadp             25443  0
vboxdrv               348377  3 vboxnetadp,vboxnetflt,vboxpci
</pre>


<p>这时候才算是真正的把所有的驱动都加进来了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[尝试hhvm]]></title>
    <link href="http://xcaptain.github.io/blog/2015/01/01/try-hhvm/"/>
    <updated>2015-01-01T00:10:28+08:00</updated>
    <id>http://xcaptain.github.io/blog/2015/01/01/try-hhvm</id>
    <content type="html"><![CDATA[<p>今天听到一个新闻说维基百科把他的php引擎由zend全面转到hhvm了，详情见<a href="https://www.mediawiki.org/wiki/HHVM">这里</a>。其实之前对于这东西是闻所未闻的，太不关注php的发展了，后来详细搜了一下，才稍微了解了一点php代码的执行过程。</p>

<p>对于动态语言来说，都是首先通过代码解析来生成字节码，然后通过解释器来执行这些字节码，php用的解释器叫作zend。看来和python差不多，程序在执行的时候也会先生成字节码，然后用python解释器去执行这些字节码。不过解释器的使用也导致了程序运行缓慢。所以现在facebook就做了一个叫作hhvm的东西，当通过hhvm来执行php程序的时候，会先生成一种中间码(intermediat byte code)也叫作HHBC(hhvm byte code)，然后hhvm会通过一种即时编译(just in time)的技术，将这种中间码编译为本地可执行的x86-64机器码，最后执行代码的时候等于是本地执行一个可执行程序，效率自然比解释器高了很多。不知道有没有什么方式能够把hhvm的这些步骤分离出来分析，真想看看php的字节码长什么样，生成的二进制程序长什么样。</p>

<p>我在本地立刻部署了一下HHVM的环境，很简单<code>sudo pacman -S hhvm</code>直接就安装hhvm了，测试一下效果，随便写一个php文件，然后<code>hhvm test.php</code>如果安装成功的话就可以得到像执行<code>php test.php</code>一样的效果，现在还没想好写个怎样的测试用例来比较hhvm和原生php的速度。</p>

<p>hhvm装好了之后当然不能只是用它来执行脚本，最重要的还是在服务器端编程上，当nginx接收到了一个请求的文件之后，并且把这个请求交个php的fastcgi处理后，在这里就不能用原生的php来执行文件里的php了，必须通过hhvm来执行，简单，就是不要启动php-fpm嘛，我看了一下安装hhvm的时候竟然自动连systemd的配置文件也生成了，所以我只要执行<code>sudo systemctl start hhvm.service</code>就能开启hhvm的监听程序了，类似php-fpm，hhvm服务器的配置文件存在<code>/etc/hhvm/server.ini</code>，在我这里配置文件写的是监听9000端口，那么<code>netstat -naltp | grep 9000</code>真的看到了一个监听的进程。然后就是确保nginx的配置文件中<code>fastcgi_pass</code>的值是<code>127.0.0.1:9000</code>，这样所有进入9000端口的数据都会被hhvm所处理。随便写了一个简单的数据库查询示例，暂时没发现hhvm和原生php的性能区别，也许是测试代码写得不好。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[采集一个论坛的帖子来进行数据分析]]></title>
    <link href="http://xcaptain.github.io/blog/2014/12/31/web-crawl-again/"/>
    <updated>2014-12-31T07:49:40+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/12/31/web-crawl-again</id>
    <content type="html"><![CDATA[<p>今天接到一个小小的需求，又是和采集相关的，我都要烦死了，采集这东西写得都要腻了。</p>

<p>不过和以前的那些采集有点区别，不再是采集文章了，而是开始采集论坛的帖子。说实话我觉得采集论坛比较简单，因为论坛都是php的页面，页面组织布局一般不会怎么变，而新闻站基本都是cms系统生成的html静态页，静态的页面就有太多可能性了，而且不排除有的编辑太敬业把每个页面都做得不一样。</p>

<p>采集源站是<a href="http://qq.100bt.com">http://qq.100bt.com</a>，和我最近做的<a href="http://www.zeze.com">zeze</a>是同一类型的东西，而且突然发现zeze竟然借鉴了很多这个网站的元素。废话不多说，这次采集主要是为了了解哪些资讯比较受欢迎，然后我们就可以有针对性的来推广我们的内容，看起来像是在收集竞争对手的信息而实现知己知彼百战不殆，这样的活我喜欢。这个叫作百田圈圈的网站似乎运营得不错，里面积累了差不多百万的帖子，用户似乎也很活跃。</p>

<p>其实要获得的信息不多，在我设计的数据库结构中包含以下字段：</p>

<pre>
tid: 帖子的id，用来作为表的主键
url: 帖子的url，便于访问
subject: 帖子标题
author_name: 楼主名，有这个东西可以用来分析哪些用户比较活跃
replies: 帖子的回复数，这个字段是用来衡量一个帖子的受欢迎程度的最重要指标
view: 帖子被查看的次数
pubdate: 发帖时间
maxpage: 帖子页数，因为有的帖子是回复楼层的，所以如果一个帖子分了很多页说明这个帖子内容丰富
category: 帖子所属分类，用来来分析哪些大类的话题比较火
</pre>


<p>没有数据库直接操作真是麻烦，上面这些数据都得分析网页去获取，而且不是在同一个页面，需求挺麻烦的但是不难。</p>

<p>代码传到<a href="https://github.com/xcaptain/BeautifulSoup_Instance/tree/master/btqq">github</a>上面了，以前写的那些采集都是用脚本的形式来实现的，这回尝试了一下自己构造一个采集类，这时候才发现对于python的面向对象特性用的太少了，在设计类的结构，接口上面都很不熟练，现在的代码设计在python大牛严重肯定是很小儿科的，以后要多学习OOP的编程思想，不能总是一个函数一个函数这样顺序的执行下来。</p>

<p>写这么一个简单的任务竟然还花了我一天的时间，看来编码能力还是有待加强，经过总结之后发现问题主要存在三方面：</p>

<ol>
<li>对mysql的查询语句不熟悉，因为我把tid设置为了主键，所以不能重复插入，我想要实现<code>insert into on duplicate key continue</code>的功能，找了半天只看到了<code>insert into on duplicate key update</code>的语法，但是后者不是我想要的，因为使用的是python的<code>MySQLdb</code>来驱动mysql的，这东西对于原生的sql语句支持不是很好，不过幸好最后我找到了<code>insert ignore into</code>这种语句，一下解决了问题，虽然<code>MySQLdb</code>在<code>execute</code>的时候会有警告，但是毕竟实现了功能。</li>
<li><code>MySQLdb</code>这个库的使用不熟悉，在用它来执行sql语句的时候出现了很多问题，看来有时间得专门总结一下python驱动mysql的方法。</li>
</ol>


<p>今晚下班回的路上突然发现代码少写了很多异常检测，比如说没有判断网络链接失败，页面匹配为空等，真希望程序能够按照我设想的执行，等明天早上到了公司6张表都给我装得满满的，明天到了公司 再去修改代码了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[通过vagrant安装coreos]]></title>
    <link href="http://xcaptain.github.io/blog/2014/12/27/install-coreos-with-vagrant/"/>
    <updated>2014-12-27T05:54:57+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/12/27/install-coreos-with-vagrant</id>
    <content type="html"><![CDATA[<p>昨晚学习了一下vagrant的用法，今天开始试着用vagrant来在本地虚拟化一个coreos的系统，等熟悉coreos的基本操作之后就可以把我现在vps的freebsd10换成coreos了。</p>

<p>按照<a href="https://coreos.com/docs/running-coreos/platforms/vagrant/">官方的教程</a>一步一步来。</p>

<ol>
<li><code>git clone https://github.com/coreos/coreos-vagrant.git</code> 会在当前目录创建一个叫做<code>coreos-vagrant</code>的目录，里面包含coreos的基本配置以及vagrant的配置。</li>
<li><p>更改配置。vagrant的配置文件就是<code>Vagrantfile</code>，这是一个ruby的文件，里面定义了2个配置文件</p>

<p> CLOUD_CONFIG_PATH = File.join(File.dirname(<strong>FILE</strong>), &ldquo;user-data&rdquo;)
 CONFIG = File.join(File.dirname(<strong>FILE</strong>), &ldquo;config.rb&rdquo;)</p></li>
</ol>


<p>一个是当前目录下的<code>user-data</code>文件，一个是当前目录下的<code>config.rb</code>文件</p>

<pre>
VirtualBox is complaining that the kernel module is not loaded. Please
run `VBoxManage --version` or open the VirtualBox GUI to see the error
message which should contain instructions on how to fix this error.
</pre>


<p>根据Vagrantfile里面 提供的url下载系统的时候，可能是url被屏蔽了，所以需要使用点小手段<code>proxychains vagrant up</code></p>

<p>但是等下载都完成之后却出现下面这段错误信息</p>

<pre>
Command: ["hostonlyif", "create"]

Stderr: 0%...
Progress state: NS_ERROR_FAILURE
VBoxManage: error: Failed to create the host-only adapter
VBoxManage: error: VBoxNetAdpCtl: Error while adding new interface: failed to open /dev/vboxnetctl: No such file or directory
VBoxManage: error: Details: code NS_ERROR_FAILURE (0x80004005), component HostNetworkInterface, interface IHostNetworkInterface
VBoxManage: error: Context: "int handleCreate(HandlerArg*, int, int*)" at line 66 of file VBoxManageHostonly.cpp
</pre>


<p>听起来是virtualbox的网卡驱动没有加载进来，在网上搜到一个很简单的方法，<code>sudo vboxreload</code></p>

<p>virtualbox的驱动问题解决之后，还是执行<code>proxychains vagrant up</code>但是这回却报错了</p>

<pre>
Bringing machine 'core-01' up with 'virtualbox' provider...
Bringing machine 'core-02' up with 'virtualbox' provider...
Bringing machine 'core-03' up with 'virtualbox' provider...
==> core-01: Checking if box 'coreos-stable' is up to date...
==> core-01: Fixed port collision for 22 => 2222. Now on port 2250.
==> core-01: Clearing any previously set network interfaces...
==> core-01: Preparing network interfaces based on configuration...
    core-01: Adapter 1: nat
    core-01: Adapter 2: hostonly
==> core-01: Forwarding ports...
    core-01: 22 => 2250 (adapter 1)
==> core-01: Running 'pre-boot' VM customizations...
==> core-01: Booting VM...
==> core-01: Waiting for machine to boot. This may take a few minutes...
    core-01: SSH address: 127.0.0.1:2250
    core-01: SSH username: core
    core-01: SSH auth method: private key
    core-01: Warning: Remote connection disconnect. Retrying...
    core-01: Warning: Remote connection disconnect. Retrying...
</pre>


<p>翻墙之后127.0.0.1是vps的内部loop地址，不是本机的，所以怎么也ssh不上去，既然东西都下载完了那就不需要代理了，直接<code>vagrant up</code>就有了下面的信息，太好了，这是在自动装系统呢。</p>

<pre>
Bringing machine 'core-01' up with 'virtualbox' provider...
Bringing machine 'core-02' up with 'virtualbox' provider...
Bringing machine 'core-03' up with 'virtualbox' provider...
==> core-01: Checking if box 'coreos-stable' is up to date...
==> core-01: There was a problem while downloading the metadata for your box
==> core-01: to check for updates. This is not an error, since it is usually due
==> core-01: to temporary network problems. This is just a warning. The problem
==> core-01: encountered was:
==> core-01:
==> core-01: Failed to connect to 2404:6800:4008:c00::80: Network is unreachable
==> core-01:
==> core-01: If you want to check for box updates, verify your network connection
==> core-01: is valid and try again.
==> core-01: VirtualBox VM is already running.
==> core-02: Importing base box 'coreos-stable'...
==> core-02: Matching MAC address for NAT networking...
==> core-02: Checking if box 'coreos-stable' is up to date...
</pre>


<p>3台虚拟机全部安装ok，我有一个集群了，哈哈哈哈。查看一下集群的运行状态。</p>

<pre>
Current machine states:

core-01                   running (virtualbox)
core-02                   running (virtualbox)
core-03                   running (virtualbox)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.
</pre>


<p>查看一下virtualbox的运行状态，有3个进程分别运行着3个虚拟机。</p>

<pre>
joey     10033  1.1  0.2 163232  9492 ?        Sl   22:33   0:08 /usr/lib/virtualbox/VBoxXPCOMIPCD
joey     10040  2.6  0.4 707156 19324 ?        Sl   22:33   0:20 /usr/lib/virtualbox/VBoxSVC --auto-shutdown
joey     11184  3.8  1.9 1497696 74992 ?       Sl   22:33   0:28 /usr/lib/virtualbox/VBoxHeadless --comment coreos-vagrant_core-01_1419632903871_39166 --startvm 29a5b99b-dfa8-48e6-b18f-d63b01696df2 --vrde config
joey     11204  0.0  0.2 154828  9228 ?        S    22:33   0:00 /usr/lib/virtualbox/VBoxNetDHCP --ip-address 192.168.56.100 --lower-ip 192.168.56.101 --mac-address 08:00:27:AA:0D:77 --netmask 255.255.255.0 --network HostInterfaceNetworking-vboxnet0 --trunk-name vboxnet0 --trunk-type netflt --upper-ip 192.168.56.254
joey     27124 10.2  1.9 1527828 76788 ?       Sl   22:40   0:32 /usr/lib/virtualbox/VBoxHeadless --comment coreos-vagrant_core-02_1419633622663_70678 --startvm 07c05704-61e7-4e61-bebd-723978180348 --vrde config
joey     28280 17.8  2.0 1523732 81576 ?       Sl   22:43   0:28 /usr/lib/virtualbox/VBoxHeadless --comment coreos-vagrant_core-03_1419633784764_52573 --startvm f614df63-7556-45ac-a4ca-3654d6039d3d --vrde config
joey     29297  0.0  0.0  12384  2400 pts/2    R+   22:45   0:00 grep --color=auto -i virtualbox
</pre>


<p>再看一下我的<code>VirtualBox VMs</code>目录：</p>

<pre>
coreos-vagrant_core-01_1419632903871_39166/  coreos-vagrant_core-03_1419633784764_52573/
coreos-vagrant_core-02_1419633622663_70678/  Public_default_1419540157403_62624/
</pre>


<p>昨天还只有<code>Public_default_1419540157403_62624/</code>一个目录，今天就多了3个了，算上昨天的那个ubuntu12.04，我是不是有4个虚拟系统了？</p>

<p>进入到我的<code>Vagrantfile</code>所在的目录，执行<code>vagrant ssh core-01</code>，就登陆进我的第一个虚拟机了。</p>

<p>剩下的就是学习如何使用coreos在上面部署开发环境了，有vagrant这么方便的工具来管理虚拟机，我都不想去研究docker了，我这样一个菜鸟竟然也能管理4台机器，科技真是使人懒惰。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一次接触虚拟化]]></title>
    <link href="http://xcaptain.github.io/blog/2014/12/26/learn-virtualization-1/"/>
    <updated>2014-12-26T04:27:01+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/12/26/learn-virtualization-1</id>
    <content type="html"><![CDATA[<p>之前在我的vps上部署了一个<a href="http://f.joxy.org">php论坛</a>，但是后来这个框架的<a href="https://github.com/esotalk/">创始人</a>突然在github上宣布重构了<a href="https://github.com/esotalk/esoTalk">esotalk</a>的代码做了一个新的论坛框架<a href="https://github.com/flarum/core">Flarum</a>，搞得我很伤心，后来在<a href="https://en.wikipedia.org/wiki/Comparison_of_Internet_forum_software">wiki</a>上看到介绍discourse，它的作者<a href="http://www.codinghorror.com/blog">Jeff Atwood</a>说discourse是未来十年互联网论坛发展的趋势，那就搭一个来看看呗，反正以前也学过一阵子ruby on rails.</p>

<p>按照原来部署<a href="http://f.joxy.org">http://f.joxy.org</a>的模式打算先在本地部署好环境，然后提交到git server然后在线上拷贝一份代码到服务器上。但是看discourse的官方安装文档的时候发现默认是不支持在实体机上安装系统的，官方的文档只支持通过docker来部署discourse，docker久仰大名了但是就是没有用过，那好，就去见识见识呗。</p>

<p>搜索了一下发现现在比较流行的服务器环境配置，服务器管理都是通过container也就是容器来进行的，最老土的服务器管理方式是通过ssh连接上服务器，然后手动编译或者包管理的形式安装软件。但是这种方式有很大的局限性，不易把所有的机器都统一配置，因为所有配置文件都要由手动编辑，然后手动更新，必然有的机器版本早，有的机器版本晚，对于管理一个服务器集群来说这是很不方便的。而且服务器多了软件更新就是一个麻烦事，不可能一台机器一台机器的去更新。</p>

<p>目前找到了3个比较有名的虚拟化技术：</p>

<ol>
<li>docker， 更类似于chroot</li>
<li>vagrant，用来管理virtualbox虚拟机</li>
<li>rocket，暂时没什么太多了解</li>
</ol>


<p>早上出门的时候在youtube上看了一个通过docker来安装coreos的视频，但是感觉要学习yaml语法配置，比较繁琐，那就先来看看vagrant吧。</p>

<p>在vagrant的<a href="http://docs.vagrantup.com/v2/getting-started/index.html">官方文档</a>上找到了简单的使用方法，其实说白了就是一个自动安装运行virtualbox的脚本。首先得安装vagrant，<code>sudo pacman -S vagrant</code>，然后得安装virtualbox，<code>sudo pacman -S virtualbox</code>，然后还得安装一大堆的依赖，<code>sudo pacman -S virtualbox-host-modules</code>是用来安装virtualbox用来和宿主机通信的模块，如果这个软件太老了就会无法正常使用vagrant，那么一个补救措施就是<code>sudo pacman -S virtualbox-host-dkms</code>，virtualbox安装好了之后还得解决一些内核的驱动，最简单的就是<code>sudo dkms autoinstall</code>，这个命令会自动搜索<code>linux-headers</code>然后编译对应的驱动，如果系统上没有装<code>linux-header</code>那么还是会报错的，那就得<code>sudo pacman -S linux-headers</code>。需要安装的软件，驱动，都装好了之后就是在内核加载virtualbox的驱动了，很简单<code>sudo modprobe vboxdrv</code>，这时候就大功告成了。</p>

<p>对照着教程在自己的笔记本上一步一步的做，先<code>vagrant init hashicorp/precise32</code>，这回在当前的目录下创建一个叫作<code>Vagrantfile</code>的文件，这里面包含了一大堆虚拟机的配置信息。然后<code>vagrant up</code>就会启动虚拟机，这时候<code>ps aux | grep -i virtualbox</code>就会发现virtualbox已经自动在运行了，在家目录的<code>VirtualBox\ VMs/</code>目录下也会创建对应虚拟机的目录，但是没有启动那个讨厌的图形界面这很不错。因为vagrant主要是用来配置服务器的，所以不需要图形界面，等系统下载安装好了之后就可以执行<code>vagrant up</code>来启动虚拟机了，这个操作会检测是否有<code>Vagrantfile</code>里面写的系统，如果没有就会自动从网上下载。系统下完之后<code>vagrant ssh</code>可以远程连接上虚拟机，发现虚拟机上面有一个网卡ip是<code>10.0.2.15</code>，好奇怪的东西，联网方式是NAT还是bridge呢？有一个自动安装系统的脚本，叫作<code>postinstall.sh</code>，以root身份执行它会自动安装系统，等最后跑完的时候吓我一大跳</p>

<pre><code>++ rm -f '/home/vagrant/*.iso' /home/vagrant/postinstall.sh
++ dd if=/dev/zero of=/EMPTY bs=1M
dd: writing `/EMPTY': No space left on device
78697+0 records in
78696+0 records out
82518818816 bytes (83 GB) copied, 207.558 s, 398 MB/s
++ rm -f /EMPTY
++ exit
</code></pre>

<p>一下dd我83G的硬盘，这可是我整个宿主机所有的空间了，不会影响到我吧，后来<code>df -h</code>了一下才发现虚拟机没有使用多少硬盘空间，而且宿主机也没有消耗掉很多硬盘空间。这样就有了一台虚拟机了，这可比直接用virtualbox方便多了，没有预先问我分配多少颗CPU，没有问我分配多少RAM，没有问我分配多少硬盘就把系统装好了，我喜欢。</p>

<p>vagrant有一个共享目录就是宿主机的<code>Vagrantfile</code>所在的那个目录，也是虚拟机的<code>/vagrant</code>目录，这个目录双方都可以读写，想想真是有点小激动，要是以后我虚拟一个windows出来在上面跑一个qq，然后今天志军通过qq传给我的《刺杀金正恩》就不用在windows上跑着vlc服务器给我的arch笔记本供源了，不知道有没有人为vagrant做windows的box。</p>

<p>不过vagrant毕竟是建立在virtualbox之上的，虽然说虚拟机占用宿主机的资源少了，但是还可以做得更好，要让机器资源更加充分的利用就得学习docker了，加油。</p>

<p>另外今天和小青谈了一下学习方式的问题，他说我三天打鱼两天晒网没有持之以恒的做一件事，想想也确实是这样，从工作开始学习和使用php来干活，python是原来就会的所以也就没有怎么学，但是又学了几个礼拜ruby，学了几个礼拜haskell，工作在二次开发discuz，但是业余时间却自己搭了一个esotalk的论坛，现在又在研究虚拟化技术。虽然我一直认为身为一个互联网从业者就得把握住互联网的发展方向，不断学习最新的技术，我们生活在一个很开放的社会，最新最热的技术都是开源的有详细的文档，如果不去学习不去研究而是抱着把会的东西研究透彻的话，我有种辜负了这个时代的感觉。希望时代别辜负了我。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何使用emacs]]></title>
    <link href="http://xcaptain.github.io/blog/2014/12/20/how-to-use-emacs/"/>
    <updated>2014-12-20T19:44:35+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/12/20/how-to-use-emacs</id>
    <content type="html"><![CDATA[<p>今天闲着没事，又上我们的<a href="https://github.com/ncuopen">ncuopen</a>上面看了一下，发现小组现在活动极其不频繁，首页和wiki都没有怎么更新，然后上irc上看了一下，发现也没有人在线。</p>

<blockquote><p>一个开源社区最大的悲哀就是没有活跃的用户，没有一个持续贡献的志愿者团队。</p></blockquote>

<p>加入小组这么久了都没有做什么贡献真是惭愧，今天想了一下我可以整理一下我对于emacs使用的一点小小的心得。以下将会简单的说说我平时使用emacs来干什么。</p>

<ol>
<li>写代码，这是最基本的功能。</li>
<li>上网，在emacs24之前的版本必须使用一个叫做<code>emacs-w3m</code>的第三方扩展才能在emacs里面上网，但是现在emacs自己做了一个基于elisp写的文本浏览器<code>eww</code>，使用方式也很简单，直接<code>M-x eww</code>然后输入要搜索的内容或者是要打开的url就行，现在<code>eww</code>默认的搜索引擎是<code>duckduckgo</code>。</li>
<li>聊天，今天上<code>#ncuopen</code>上看了一下，发现聊天室里面没人在，突然比较一下那些比较火的聊天室，如<code>ubuntu</code>, <code>debian</code>每天上去都会有一大堆人在线，随便说一句话就会被别人刷屏，差距真的很大。如果要在emacs里面使用irc聊天，可以使用<code>erc</code>来连接服务器。</li>
<li>看pdf，emacs内建是可以打开pdf文件的，如果习惯了emacs的快捷键，而且不喜欢在<code>evince</code>，<code>okular</code>下面必须使用鼠标的操作，那么可以试试用emacs看pdf。</li>
<li>写博客，我自己也在github上面搭了一个octopress的博客，在本地就是用emacs编辑的博客，因为emacs支持<code>markdown</code>语法，编辑的时候可以直接看到语法高亮，保存后可以在本地预览。</li>
<li>执行shell命令，要么是使用<code>M-x shell</code>来打开一个shell或者是<code>M-x eshell</code>来使用emacs自带的终端模拟器，我喜欢用后者，然后就可以运行任何的shell命令了。不过我用eshell用得少，平时都是在<code>urxvt</code>里面执行命令的。</li>
<li>执行解释器，很动语言都内建了一个elpa的解释器，如ruby, python, php, haskell，sml等，如果想尝试一下某个表达式或者是某个代码段又不想写一个测试文件，那么在解释器里运行是最方便的了，执行<code>M-x run-python</code>, <code>M-x run-haskell</code>，会打开对应语言的解释器，就像在终端执行一样。如果想获得更多语言的支持，可以去<a href="http://elpa.gnu.org/packages/">elpa</a>或者是<a href="http://melpa.org/">melpa</a>上面找找。</li>
<li>使用git，emacs有个扩展叫做<code>magit</code>，用它来提交代码，查看差异，查看版本比在终端使用git命令方便。</li>
<li>看图，这个功能估计很少人会用，<code>display</code>和<code>feh</code>已经做得很棒了。</li>
</ol>


<p>如果要使用上面的功能，最好使用<a href="https://github.com/bbatsov/prelude">prelude-emacs</a>上面的配置，省去很多配置的麻烦。</p>

<p>另外我发现现在小组没有一个好的交流的地方，在github上面提issue总是不太方便，找到了一个开源项目<a href="https://github.com/esotalk/esoTalk">esotalk</a>可以很方便的用来搭建论坛，不知道有没有小伙伴愿意贡献一下。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[又是一个采集]]></title>
    <link href="http://xcaptain.github.io/blog/2014/12/08/learn-beautifulsoup/"/>
    <updated>2014-12-08T06:25:45+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/12/08/learn-beautifulsoup</id>
    <content type="html"><![CDATA[<p>前几天看到有个同事在采集<a href="https://yande.re">这个</a>站，要把上面的图片都搞下来。看他很得意的样子，似乎采集是个什么很复杂东西，其实简单得很，没什么技术含量在里面。他用的是一个叫做scrapy的采集框架，这个框架我没用过，但是自己写采集也简单。</p>

<p>之前采集过多玩和178的一些文章，需求还比较复杂，需要把ajax的接口也给搞定掉，还得把所有图片都本地化，那时候用的是urllib2+beautifulsoup这个东西采集的。</p>

<p>今天闲着没事，打算再来搞个采集玩玩，<a href="https://yande.re">yande</a>上面的图片质量还是比较高的。还是使用老一套，不过这回我不打算使用urllib2了，这东西太弱了，编码问题总是会出现，搞得我莫名其妙的，实在是打算放弃urllib2了，上网搜一下，找到了一个叫做<code>requests</code>的网络库，这个东西目前开发还是蛮活跃的，而且口气比较大，直接在官网说urllib2的api很混乱，那就是它了。页面分析的库还是用回beautifulsoup，这么久了仍然是很不喜欢写正则，所以拿这个库来解析html还是比较顺手。至于信息入库，我用的是<code>MySQLdb</code>这个库来驱动mysql，似乎这个库也比较弱，反正我是遇到很多很简单的sql语句都报错的情况了，在网上搜了一下，发现别的第三方的mysql库也很多，但是还没有下定决心换。</p>

<p>代码的思路很简单，和以前写的采集脚本差不多，都是先采集列表页，获得文章页的url，然后在文章页中采集想要的信息。信息采集完了就是入库，到这里采集过程就结束了。</p>

<p>代码很简单，已经提交到<a href="https://github.com/xcaptain/yande">github</a>了，和之前写的脚本比起来，多增加了一些东西：
1. 模糊匹配，比如说<code>soup.find(href=re.compile('user\/show'))</code>这样的东西。
2. 断点续踩，程序在跑的时候如果按下<code>Ctrl-C</code>来终止它的话，会把当前采集到的页码写入到一个叫做<code>config.py</code>的文件。
3. 异常处理，以前写的几个采集使用了很多if语句，很多嵌套的判断，就是为了人为规避异常，尽量让程序跑的时候都不遇到异常，这种写法真是太折磨人了，看到三四层嵌套判断我的头都要大了。这回尝试了一下直接在<code>try</code>里面执行代码段，如果遇到可能会有的异常就直接<code>except</code>上处理了它，真是省了很多心呀。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[入手一台二手PC]]></title>
    <link href="http://xcaptain.github.io/blog/2014/11/24/got-an-old-pc/"/>
    <updated>2014-11-24T05:09:30+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/11/24/got-an-old-pc</id>
    <content type="html"><![CDATA[<p>今天下午在58上面看到一条消息，说的是190出售双核电脑，立即就心动了。作为一个linux，总是忍不住手痒想重装系统，或者是自定义系统，但是因为现在自己手头上只有一台笔记本，实在是不敢轻举妄动，不然把这电脑弄崩溃了，或者是丢失数据了那就损失惨重了。如果有一台空闲的机器那就好了，我可以随便在那台机器上面装系统，可以随意定制。而且有一台局域网内部的PC当作服务器，拿来当测试机很不错，在这里测试过代码之后再上传到线上vps上去。</p>

<p>说干就干，反正190也不贵，现在出去随便找个饭店吃个稍微好点的饭都不止190.给卖家打了电话先问了一下基本的情况，大致确定了消息的真实性，然后就是出发去验货了。那个卖家在东城区，好远啊，看了一下时间都已经3点半了，赶紧出发。又是转公交又是转地铁，终于到了东四北大街，来到了卖家的家里。太震惊了，卖家竟然是一个50多岁的老头，家里很简陋，胡同里很老的房子，但是里面堆满了电脑主机，估计有2,3百台。我要买的那台电脑正开着呢，装着win7系统，正在通过pptv看视频呢。cpu是amd的，1.9GHZ，ddr2内存1G大，网卡是100M的螃蟹卡，这种网卡对于*unix来说几乎都是免驱动的了，使用的太广泛了。剩下的就没什么说了，反正是打算拿来当服务器的，对于显卡没什么要求。</p>

<p>成交之后就抱着这主机又穿过了大半个北京回到了住的地方，累死我了。</p>

<p>回来之后打算装系统，问了一下群里的几个朋友，他们都说要装系统的话必须要有显示器才行。伤心，我还以为有一键安装系统的脚本呢，看来系统是得下周拿到公司去装了。真搞不懂，如果服务器装机也像普通桌面电脑一样的话，那些大公司的运维该多惨，几百台机器得装。</p>

<p>接下来就是得好好想想服务器装什么系统好了，现在vps上跑的是freebsd10,已经连续运行3个多月了，稳定性还可以。但是我自己桌面装的是archlinux，相对来说arch的用法还是比freebsd要简单得多。说到这里又想到这几天debian多位核心开发者离职，好像就是因为debian8要采用systemd的原因。arch很早就用了systemd来管理系统启动进程，导致现在用arch几乎都是傻瓜式了，开启某个软件，安装某个软件，检测某个进程运行状态，都可以通过systemctl来实现。对于*inux的哲学来说还是一个软件只干一件事，对于这种想把什么事都干掉的软件，freebsd是很抵制的。</p>

<p>真搞不懂到底哪种才是对的。</p>

<p>昨天在公司加班终于把zeze的代码部署到git上了。</p>

<p>之前用的版本管理是svn，但是我不太喜欢svn，因为emacs不支持它。我喜欢git，因为emacs对git的支持很好，通过magit我可以很轻松的看到每个版本之间的改动，可以任意提交代码。其实我也不是很熟悉git，但是得慢慢来学，以后git肯定是会取代svn的。</p>

<p>我把svn里面的代码复制到内网测试机之后，<code>git init</code>了这个目录，然后执行初始化提交，然后在本地执行<code>git clone user@host:/project/ ./project</code>把代码拷到了本地，打算在本地改了之后up到服务器上。但是后来我发现我想多了，git不是svn，用svn的这种思路是行不通的，线上的代码和本地的代码是毫无关系的2个分支，本地改了之后提交执行<code>git push</code>是会报错的。</p>

<p>那么什么才是正确的git方式呢？查看了一下git的文档，发现上面说git有一个版本库，克隆这个版本库就能获得最新的版本。</p>

<ol>
<li>先把代码复制到本地，<code>scp -r online_code local_code</code></li>
<li>把本地代码初始化成一个git仓库，<code>git init</code></li>
<li>把本地代码都加入到git版本中，<code>git add .</code></li>
<li>第一次提交代码，<code>git commit -m 'init commit'</code></li>
<li>把本地仓库推送到远程服务器上，<code>git remote add gituser@gitserver:/local_code.git</code>，在执行这步的时候必须确保git服务器上面已经存在local_code.git这个目录，如果不存在的话就得<code>mkdir local_code.git</code></li>
<li>把本地仓库保存的版本都推送到服务器上，<code>git push origin master</code></li>
<li>ssh上git服务器看看，找到local_code.git这个目录，发现里面的文件竟然和本地代码里面<code>local_code/.git/</code>下的内容一模一样</li>
<li>把仓库里的代码克隆到对外访问的环境，因为我是在本地做的测试，所以代码仓库和web服务器是在同一台机器上的，直接执行<code>git clone local_code.git /srv/http/online_code</code>就把版本库里面记录的代码复制出来放到服务器目录了。</li>
</ol>


<p>之前我直接在服务器上写代码，提交代码的时候真是落后，得通过命令行来提交代码，magit没法判断远程服务器上的代码的版本。现在这样就好了，我可以用magit随时commit,随时push，然后只要到<code>/srv/http/online_code/</code>下面<code>git pull</code>就行了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我的第一块机械键盘]]></title>
    <link href="http://xcaptain.github.io/blog/2014/11/10/my-first-machanical-keyboard/"/>
    <updated>2014-11-10T01:25:52+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/11/10/my-first-machanical-keyboard</id>
    <content type="html"><![CDATA[<p>考虑良久，今天终于入手了一块机械键盘。对机械键盘发烧得从上周开始说起，看到一个同事用机械键盘，感觉太爽了，顿时自己也想买一个，然后就是在网上搜相关的信息。</p>

<h3>在网上了解到了很多机械键盘相关的信息，突然发现小小的键盘里面竟然有这么多内幕。</h3>

<ul>
<li><p>对于程序员来说HHKB当然是首选，但是高昂的价格让人望而生畏。</p></li>
<li><p>然后就是传说中的<a href="http://codekeyboards.com/">codekeyboard</a>，不过，这款键盘国内没得卖，而且在国外估计也是小众，还是以后再考虑吧。</p></li>
<li><p>还有一个很牛的键盘叫做<a href="http://www.daskeyboard.com/">daskeyboard</a>，这款键盘的创造者也是一个程序员大牛，具体的来源可以参考一下<a href="http://en.wikipedia.org/wiki/Das_Keyboard">wikipedia</a>，不过我不喜欢104键的键盘，而且价格也不便宜。</p></li>
<li><p>接下来就是一些很普通的键盘了，网上说机械键盘最重要的就是轴(switch)，最好的轴当然是德国樱桃(cherry)的原厂轴了。现在主要的樱桃轴是按照颜色来分的，有红轴(red switch)，黑轴(black switch)，青轴(blue switch)，茶轴(brown switch)，以及一些不太起眼的轴。在这四大主力轴中，黑轴公认的玩游戏最爽，红轴声音小，直上直下，青轴最吵，不过打字最爽。茶轴介于青轴和红轴之间，是新出的一款轴。</p></li>
</ul>


<p>我的这款poker 2是kbc产的，一个国产品牌，但是不得不说做工很不错，小巧紧凑，该有的功能都有了，以后估计可以纯键盘办公了。87和104一个很大的区别就是没有小键盘，所以要按方向键，翻页键都得通过FN组合来实现。对我来说有点不方便，因为我的urxvt的设定是<code>shift+downarrow</code>来实现新建标签的，已经习惯这种快捷键了。现在得按<code>shift+fn+s</code>才能打开一个新的urxvt标签，在考虑是改改urxvt的设置还是改改键盘映射。</p>

<p>底下的win键倒是很符合我的需要。现在用的是xmonad的窗口管理器，我之前设置的快捷键是<code>mod1mask+[1..9]</code>来切换窗口的，现在不需要怎么改就能直接用win键。</p>

<p>打开火狐浏览器的时候突然发现没有上下方向键不好滚动页面了，而且没有了左方向键回到前一页也不方便了。不过发现了一个解决办法。要滚动页面可以考虑<code>fn+[s,w]</code>，或者是<code>[fn+space]然后[w,s]</code>。因为[fn+space]会把asdw变成方向键。要回到前一个页面就不太方便了，我想了一下可以把<code>[backspace]</code>设置为回到前一页的快捷键。不过这个得改firefox的快捷键设置。在地址栏输入<code>about:config</code>，然后找到<code>browser.backspace_action</code>，我这里默认的是2,也就是说shift加左箭头可以回到前一页，不过我想把这个值设置为0,这样就是<code>backspace</code>来回到前一页了。</p>

<p>几个大按键不太好，声音和普通按键不同，有点滞胀感。问了卖家，他说这是正常情况，因为大的shift用了一个平衡杆来感应按键，虽然很不爽，但是还是忍忍吧，以后有钱了买个好的键盘，现在这个就先拿来练练手。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis崩溃]]></title>
    <link href="http://xcaptain.github.io/blog/2014/11/02/redis-crash/"/>
    <updated>2014-11-02T08:36:37+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/11/02/redis-crash</id>
    <content type="html"><![CDATA[<p>星期五上班的时候运维报告说有一台redis服务器的流量出现异常，接收到的流量非常高，主要是来自另外一台服务器的。然后又给出了这台服务器上<code>netstat -nt | grep -i 'time_wait'</code>的结果，发现1000多个time_wait的进程，太恐怖了，连接的丢包率这么高，是不是说明redis性能很低了呢？</p>

<p>telnet上redis服务器去查看了一下，也就10万+的key，按理来说不应该这么慢。后来事故达到高峰期了，好几个站出现502了，这时候运维报告redis服务器网卡io达到峰值，太恐怖了，服务器使用的是1000Mbps的网卡，每秒钟redis读写超过1G了，怎么会这样？这时候看来就好理解之前netstat的结果了，既然网卡达到上限了，肯定服务器就不能即使返回请求。</p>

<p>redis读写过高我们分析可能原因是写入了很巨大的key，在redis里面monitor了一下最近的读写状况，发现大部分都是get一些很小的key，一般都是一些比较小的数组，既没有缓存文件，也没有缓存大段的页面，那么为什么会出现流量过高呢？我觉得很大的原因是redis真的出现性能问题了，如果性能下降了的话，而请求数又没变，也是会导致time_wait的。其实我早就发现我们现在编码很不规范，redis有5种数据结构，但是在大部分业务中都只用到了1种数据结构，也就是字符串。不得不说这是一个很傻的设计。在10几万的key中get一个key得有多慢，如果设计一些hash表，把不同的key存到hash里面，那么可以大大的提高redis的性能，毕竟redis的key大大的减少了，而在hash表里面查询某个key的值还是比较快的。肯定比在redis库里查询快。不过知道问题所在不意味着我们会去改，现在开发人员本来就少，但是新的项目一个接一个。目前简单测试了一下没问题就上线了，根本没有考虑过代码的性能问题，没有人审核代码，没有人压力测试代码，在开发的时候怎么省事怎么来，之前别人写的方法copy过来直接用，也不管之前的代码和现在的代码处理的问题有多不同，只要能用那就可以。</p>

<p>这也是没办法的办法，可以做的不多，后来他们把一些代码的缓存时间缩短了，这样就不会有太多的key留在内存中，减少key的数量之后大概能加快一点查询效率。而且他们还审查了一部分代码，我看了他们找的一个文件，有个程序会一次性请求7个接口获得一大堆数据，但是真正有用的只是其中一部分，后来他们优化了一下，在取数据之前加了一些判断来觉得到底去取哪个数据。看起来效果挺明显的，至少这个文件的请求就少了7倍。</p>

<p>顺便再来总结一下netstat(network statistics)的用法吧，用它来监控网络状况挺好的。
1. 直接执行<code>netstat</code>，会输出当前所有的连接。
2. <code>netstat -a</code>，输出所有的连接，和<code>netstat</code>的结果一样。
3. <code>netstat -t</code>，列出所有的tcp连接。
4. <code>netstat -i</code>，列出当前所有的网络接口，比如说我的笔记本有3个接口，一块以太网卡，一块无线网卡，一个回环接口。
5. <code>netstat -s</code>，列出当前所有协议的统计状态，包括tcp, ip, udp, icmp等。
6. <code>netstat -p</code>，列出进程名以及对应的pid。
7. <code>netstat -r</code>，列出当前的路由表。</p>

<p>主要得分析一下<code>netstat -a</code>的输出，这个连接状态太多了，得好好研究一下。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[调试discuz（一）]]></title>
    <link href="http://xcaptain.github.io/blog/2014/11/02/debug-discuz-1/"/>
    <updated>2014-11-02T07:40:57+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/11/02/debug-discuz-1</id>
    <content type="html"><![CDATA[<p>现在他们在做一个论坛，因为人手不够，所以最后决定使用discuz来快速搭建一个论坛。我是很反感这种做法的，大公司怎么会用discuz来搭建自己的社区呢？太丢脸了，这不是告诉别人你没有研发能力吗？不过现在我们这边的研发能力确实很弱，公司不是研发型的，太悲哀了。</p>

<p>我以前从没有接触过discuz，第一次碰到感觉压力很大，什么数据字典，缓存结构，插件机制，模板机制我都不懂，最初他们只叫我做了一点简单的部署问题，比如改个nginx的rewrite规则，改个简单的模板样式，不过渐渐的麻烦的任务也来了。</p>

<p>首先是说他们买了一个模板（真够丢人的），但是这个模板是被加密了的，现在要稍微二次开发一下，比如说改一些url的规则，使得url更加seo友好。其实模板上的url还是很好改的，模板改了之后再加点rewrite到nginx就好了。但是在分页上的url就不好改了，需要去看插件是如何获得数据，输出数据的，结果可恨的是这个插件的开发者把取数据，传数据的过程都给加密了，让人非常郁闷。到最后甚至一度想要把这些加密的方法破解了，不过到底不可能花太多时间去破解，干活才是最重要的。</p>

<p>调了一晚上，终于发现了插件在实现分页的时候调用到了一个discuz的分页函数，在<code>source/function/</code>里面执行<code>grep 'multi' -R *</code>在<code>function_core.php</code>这个文件里找到了multi这个函数，然后发现这个函数调用了<code>helper_page::multi</code>这个函数，继续找这个函数。首先找<code>helper_page</code>这个类，那就去<code>source/class/</code>里面找，<code>grep 'multi' -R *</code>在<code>helper/helper_page.php</code>里面找到了multi这个静态方法。接下来就是改造这个方法了。大致看了一下，这个函数接受一个url，一个当前页码，以及一些不太重要的东西作为参数，最后输出一段分页代码。在生成html的时候调用到了一个叫做<code>mpurl</code>的方法，这个函数会决定使用什么形式的分隔符来输出url。到这里形势大概就很明朗了，我不必要去改分页函数的逻辑，我只要改<code>mpurl</code>这个函数就好了，如果是这个插件的url，我就让这个函数特殊照顾一下这个插件。</p>

<p>那么现在问题来了，我是该怎么去改造这个函数呢？在它里面加判断？外面加判断？重写一个自定义的函数？我的想法是加入一个自定义的分页函数，<code>multi</code>在调用<code>mpurl</code>的时候会判断一下是调用它还是调用我写的自定义的函数。我想要通过函数名复制来实现，但是我不知道在php里怎么做，所以我就去<a href="http://stackoverflow.com/questions/26657161/can-i-assign-a-function-in-php">stackoverflow</a>上问了一下，有个家伙说可以通过变量来保存函数名，比如说<code>$func = 'add';</code>，那么<code>$func(1,2);</code>就等同于<code>add(1,2);</code>了。这个方法有点函数式编程的意思了，不过还是不够，本质上不属于函数名赋值，而且对于调用类里的方法不起作用，我尝试着<code>$func = 'self::add'</code>，然后发现总是会报错。后来采用了另一个家伙的方法，写一个帮助函数，在这个帮助函数里面会判断到底是使用dz原生的<code>mpurl</code>还是使用我的<code>my_mpurl</code>，这个方法挺好，我照着做了，终于把分页搞定了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[学习haskell（二）]]></title>
    <link href="http://xcaptain.github.io/blog/2014/10/27/learn-haskell-2/"/>
    <updated>2014-10-27T01:13:53+08:00</updated>
    <id>http://xcaptain.github.io/blog/2014/10/27/learn-haskell-2</id>
    <content type="html"><![CDATA[<p>今天发现一件很有趣的事，我在ghci下输入<code>:i zip</code>来查看zip这个函数的用法的时候得到的结果是<code>zip :: [a] -&gt; [b] -&gt; [(a, b)]   -- Defined in ‘GHC.List’</code>，zip明明是接收2个列表作为参数，然后一个元组的列表，但是根据这个输出，感觉zip是先处理列表[a]，然后再处理列表[b]，最后得到一个得到一个列表[(a, b)]。</p>

<p>为了验证我的猜想，先试<code>zip [1,2,3] [3,2,1]</code> 得到 <code>[(1,3),(2,2),(3,1)]</code>。这是意料之中的，zip的作用就是这个。</p>

<p>然后再试验：<code>(zip [1,2,3]) [3,2,1]</code> 得到 <code>[(1,3),(2,2),(3,1)]</code>，在这个函数调用中，我用括号把前一部分括起来了，也就是说先处理一个列表，然后返回一个函数再处理另一个列表。很奇怪，在实际函数调用中使用的是什么顺序来求值的呢？</p>

<p>在<a href="http://stackoverflow.com/questions/26571897/haskell-function-invoke-order">stackoverflow</a>上面问了一下这个问题，原来这种现象有一个专业术语叫作<a href="http://en.wikipedia.org/wiki/Currying">currying</a>，也就是说函数如何处理多个参数。没有看到后面就问问题还是比较尴尬的，在haskell里面大名鼎鼎的术语都不知道，太丢人了。</p>

<p>后来我在搜索curry的时候还发现了<a href="http://www-history.mcs.st-andrews.ac.uk/Biographies/Curry.html">Haskell Brooks Curry</a>这个人，haskell就是以他的名字命名的，真是牛得不行的一个家伙，16岁上哈佛，先是学医，后来又转学数学，后来有修了一个物理学的硕士，博士又开始搞数学，开始是打算写偏微分方面的论文的，到最后发现兴趣在逻辑学上，就转而研究逻辑去了。在40岁的时候成为了世界上最有名的逻辑学家。haskell的爱好者看起来都有很强的数理逻辑的背景啊，对于写过程式的代码也许真会越写越傻，因为思维到最后都变成机器的思维了。</p>

<p>还有一件很有意思的事就是惰性求值，在别的语言里可真是不多见。所谓的惰性求值就是如果这个变量没有被用到那就不会去求值。比如说<code>let a = 1</code>，在这里定义了一个变量a，但是其实这时候a还没有求值，只有在我们调用a的时候才会打印它的值。再比如说<code>let a = cycle [1,2,3]</code>，这会一直循环[1,2,3]这个列表，但是如果我们不去调用a就没关系，反正不调用就没有值。或者我们<code>take 10 a</code>，就会得到返回列表的前10个值，在这里调用了a，但是在求值的时候只用到了前10个，所以a没有一直循环下去。别的语言有这种定义无限个元素的列表的能力吗？别的语言有惰性求值的能力吗？</p>
]]></content>
  </entry>
  
</feed>
