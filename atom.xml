<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Joey's Blog]]></title>
  <link href="http://blog.joxy.org/atom.xml" rel="self"/>
  <link href="http://blog.joxy.org/"/>
  <updated>2015-05-04T13:03:01+08:00</updated>
  <id>http://blog.joxy.org/</id>
  <author>
    <name><![CDATA[joey]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mysql基础]]></title>
    <link href="http://blog.joxy.org/blog/2015/05/03/mysql-basics-1/"/>
    <updated>2015-05-03T02:34:28+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/05/03/mysql-basics-1</id>
    <content type="html"><![CDATA[<p>五一第二天泡国图看了一下午关于sql的书，小有所获，才发现以前工作中用到的只是mysql中的一个很小的子集，该好好整理一下了基础知识了，当然对于很基本，已经用得很熟练的知识就不提了。</p>

<h3>什么是sql语言</h3>

<p>sql语言包括：
    DDL（数据定义语言）：创建数据库，创建表，创建视图，创建索引等。
    DML（数据操作语言）：也就是增删改查操作。
    DCL（数据控制语言）：COMMIT，ROLLBACK，GRANT等。</p>

<h3>聚合查询</h3>

<p>聚合查询指的是把一张表的内容分组，相关操作包括<code>count</code>, <code>sum</code>, <code>min</code>, <code>max</code>, <code>avg</code>, <code>group by</code>, <code>having</code>，前面5个是聚合函数，从一大串结果中取出我们要的属性。
后面2个是分组的。<code>group by</code>的语法为:</p>

<pre><code class="sql">select &lt;col1&gt;, &lt;col2&gt;, &lt;col3&gt;
    from &lt;table_name&gt;
[where ...]
group by &lt;col1&gt;, &lt;col2&gt;, &lt;col3&gt;
[having ...]
</code></pre>

<p>有一条限制说的是select子句中的每一个字段都必须出现在group by的子句中，但是我在mysql和postgresql中执行的时候结果确不一样，pgsql有这个限制，而mysql则松散得多。在我看来必须得严格才行，不然在有1对多关系的表中，group by之后的结果可能会让人莫名其妙，难怪很多人都说postgresql比mysql要严谨。</p>

<h3>事务</h3>

<p>事务指的是把一系列操作封装在一起来执行，要么同时执行这一些列操作，要么一个都不执行。这个以前工作也用到的不多，可能公司是以前写代码的人对于这个也不看中吧，基本上都是直接update，insert了。记得以前用python的<code>MySQLdb</code>的时候，如果有插入操作必须手动调用一下commit方法才能把数据写进数据库，那时候还不理解，感觉多了一步操作实在是太麻烦了，现在看来把所有操作都看作事务来执行，手动提交事务对于数据来说还是很安全的。</p>

<p>事务有4个特性：（ACID）</p>

<ol>
<li>原子性（Atomic）：事务是一个整体。</li>
<li>一致性（Consistency）：每个操作都必须满足对应列的约束条件。</li>
<li>隔离性（Isolation）：没一个事务中的数据对另一个事务都是不可见的，在提交操作之前，数据不在表里面。</li>
<li>持久性（Duration）：每个事务完成之后会有日志记录，方便从日志恢复数据。</li>
</ol>


<p>创建事务：</p>

<pre><code class="sql">start | begin transaction
sql1;
sql2;
...
commit
</code></pre>

<p>现在仔细想想原来看过好多同时更新多张表的代码没有走事务，那些业务真是太危险了，一张表的结构出错可能就导致整个业务逻辑崩溃。</p>

<h3>视图</h3>

<p>视图类似与一张表，但是区别是表里面存放着数据，但是视图里面没有数据。可以用</p>

<pre><code class="sql">create view &lt;视图名&gt; [&lt;col1&gt;, &lt;col2&gt;]
as
select &lt;col1&gt;, &lt;col2&gt; ...
    from
&lt;表名&gt;
</code></pre>

<p>来创建一个视图。视图主要是为调用很频繁的sql做的，省得每次都得写一大段sql，视图还可以层叠，也就是cascade，不过这功能又太偏了，单用view就已经很少了。不过不知道在view中执行查询有没有比直接在表中查询快，如果仅仅是为了sql简洁就发明视图这个概念出来那也太浪费了吧。</p>

<p>视图是子查询的基础，子查询可以看作是一个视图。</p>

<h3>表的集合操作</h3>

<p>表在关系代数中其实就是集合，所以可以交集，并集，查集。</p>

<h3>表连结</h3>

<p>以前大学的时候学离散数学，数据库原理都讲了关系代数，但是才刚刚毕业一年就几乎忘光了，到目前只知道内联接外联接，连用形式化语言来描述连接都做不到，实在是辜负大学四年了，不过现在做应用开发，基本的理论知识看起来又有点鸡肋。</p>

<p>连接分为内联接，外联接。
inner join &lt;=> join
left outer join &lt;=> left join
right outer join &lt;=> right join
尽量避免直接写outer join，这样会使语义模糊。</p>

<h3>基本查询惯例</h3>

<ol>
<li>建表的时候用<code>primary key(id)</code>来创建主键，以前我都是喜欢写在一个列的限制性约束条件后面。</li>
<li>在表明不相等关系的时候使用<code>&lt;&gt;</code>而不是<code>!=</code>，前者才是标准写法。</li>
<li><code>char</code>类型是按照字典顺序来排序的，一直以来我都以为是按照ascii的顺序来排的。</li>
<li>在建表的时候尽量避免使用NULL这个变量，因为在查询中空值比较不好处理，不好比较大小，不好做运算，不好count，我也不打算去研究NULL在各种情况下的意义。判断一个字段是否为NULL用<code>IS NULL</code>来判断。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Develop-on-docker]]></title>
    <link href="http://blog.joxy.org/blog/2015/04/21/develop-on-docker/"/>
    <updated>2015-04-21T14:02:48+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/04/21/develop-on-docker</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一个简单的元编程的例子]]></title>
    <link href="http://blog.joxy.org/blog/2015/04/17/php-meta-programming-1/"/>
    <updated>2015-04-17T17:33:16+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/04/17/php-meta-programming-1</id>
    <content type="html"><![CDATA[<p>去年在学习ruby的时候就看到了很多元编程的例子，用一个方法来生成多个类似的方法，避免制造重复的代码，ruby用的是method_missing来实现的。</p>

<p>今天工作遇到一个小问题，需要写一个简单的脚本来统计某个时间段用户的发帖信息，需求很简单要实现也很简单。最初的设计见下面：</p>

<pre><code class="php">class UpdateUserRank {
public function __construct() {}
public function getDayRank($num) {}
public function getMonthRank($num) {}
public function getAllRank($num) {}

public function setDayRank() {}
public function setMonthRank() {}
public function setAllRank() {}
}
</code></pre>

<p>需要写3个get方法，3个set方法，这种形式实在是太不方便维护了，每个函数的功能类似，而且函数名也类似，有没有什么办法能够不要写这么多函数呢？利用php的<code>__call</code>方法可以很简单的实现</p>

<pre><code class="php">class UpdateUserRank {
public function __construct() {
    $this-&gt;getMethods = array('getDayRank', 'getMonthRank', 'getAllRank');
    $this-&gt;setMethods = array('setDayRank', 'setMonthRank', 'setAllRank');
}
public function __call($name, $args) {
    if(in_array($name, $this-&gt;getMethods)) {
        $num = $args[0];
        return $this-&gt;redis-&gt;zrevrange($this-&gt;_key($name), 0, $num, true);
    } elseif(in_array($name, $this-&gt;setMethods)) {
        $nowtime = time();
        if($name == 'setDayRank') {
            $ago = $nowtime - 24 * 3600;
            $key = 'getDayRank';
        } elseif($name == 'setMonthRank') {
            $ago = $nowtime - 24 * 3600 * 30;
            $key = 'getMonthRank';
        } else {
            $ago = 0;
            $key = 'getAllRank';
        }
        $sql = "select authorid, count(authorid) as threadnum from dz_forum_thread where dateline between $ago and $nowtime group by authorid";
        $sth = $this-&gt;pdo-&gt;prepare($sql);
        $sth-&gt;execute();
        while($row = $sth-&gt;fetch(PDO::FETCH_ASSOC)) {
            $authorid = $row['authorid'];
            $threadnum = $row['threadnum'];
            $this-&gt;redis-&gt;zAdd($this-&gt;_key($key), $threadnum, $authorid);
        }
    } else {
        echo "不合法的方法: " . $name . "\n";
        exit(1);
    }
}
}
</code></pre>

<p>调用一个类里面的方法时，如果在当前类没有找到这个方法就会逐层往父类查找，直到找到对应的方法，但是如果这个类或者是父类定义了<code>__call</code>方法，则能自动处理找不到的方法，接受2个参数，第一个是函数名，第二个是函数名传过来的参数，是一个数组。基本上可以说<code>__call</code>实现了<code>method not defined</code>这个异常的处理吧。</p>

<p>因为php的正则没有ruby简单，所以在这里我先定义了2个数组，对象调用的方法必须在这2个数组中才能执行，否则就报不合法的方法，然后退出，也许还可以通过<code>__get</code>, <code>__set</code>来实现，谁知道呢？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Btrfs损坏之后的一系列麻烦]]></title>
    <link href="http://blog.joxy.org/blog/2015/03/26/btrfs-crash/"/>
    <updated>2015-03-26T23:12:37+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/03/26/btrfs-crash</id>
    <content type="html"><![CDATA[<p>上周六晚上玩电脑的时候忘记插上电源了，直接导致笔记本意外断电关机，本来这只是一件小事，重启电脑即可，个人电脑一般没有多大的磁盘IO，数据基本都是在内存中读写的，但是等我重启电脑的时候却发现没法进系统了，一直卡在fsck那步，然后就是一直提示出现多少个<code>block error</code>，心立刻亮了半截，我用的arch没有做备份，如果硬盘损坏，里面的重要文件就都没了。于是重启进入win8下载了一个system-rescue-cd打算进入livecd修复分区，进去之后执行<code>btrfs check --repair /dev/sda3</code>，倒是检查出了一个块错误，但是没有修复，尝试重启电脑，结果出现<code>bad super block, unknown fs</code>，似乎问题加重了，上网搜了一下superblock损坏的话要找备份的superblock来替换，但是我没有定时做文件系统备份，行不通，后来尝试给<code>btrfs check</code>加上<code>--init-scum</code>参数，重启之后一大堆错误，死心，对数据不报期望了。</p>

<p>上一个系统用了1年多没换，好不容易有一次机会折腾可不能放过，先尝试安装funtoo，和以前无数次一样，都是到最后驱动不了我的博通无线网卡，后面尝试sabayon这个桌面系统，自带了桌面肯定自带了所有驱动。尝试安装，这回小心了，把<code>/boot</code>单独放到一个ext2的分区中去了，然后/用的是xfs，毕竟SGI的技术还是非常可以的。安装之后果然不需要手动装驱动，这种傻瓜式操作我最喜欢了，gnome中总是配置不好fcitx，而且ghc编译的时候总是会报错，也是莫名其妙的问题，supervisor的配置都得自己手动写，一大堆反人类的事情真是头疼，被arch的KISS哲学熏陶得simple且stupid之后，实在是受不了gentoo的diy思想。用<code>btrfs restore /mnt/arch /mnt/arch_bak</code>备份大部分数据之后，继续重装arch。</p>

<p>备份分区之后就多出了一个分区可以用来安装第三个系统，对于懒人来说肯定不愿意折腾文本安装界面，直接下载antergos的livecd开始图形化安装，一步一步做，选文件系统的时候还是不死心，不愿意放弃心爱的btrfs，又做死选了它。系统倒是很快就装好了，麻烦的地方是配置，不过默认的gnome3界面用得真心不习惯，所有应用窗口挤在一个桌面上，反复切换实在是太麻烦了。在安装fcitx输入法的时候不小心<code>systemctl stop dbus.service</code>，结果gnome桌面自动推出了，卡在一个黑乎乎的界面，对于一切操作都没有响应，强制关机之后发现又进不了硬盘了，满头黑线。</p>

<p>反正这个新安装的系统没有什么数据，重装即可，这回发誓在也不用btrfs了，试试ext4这个根正苗红的linux传人，果然一切OK，有线无线网卡自动激活，电源管理自带，安装xmonad没问题，安装fcitx一切顺利，安装dmenu用来管理菜单，安装urxvt，复制之前的Xresources文件，安装fish，安装vim，安装emacs，安装supervisor，安装shadowsocks，安装proxychains，github上面拷贝spf13的vim配置，prelude的emacs配置，oh-my-fish，一切都是这么简单，几乎不需要自己做额外的配置。进入熟悉的xmonad界面之后内心久久不能平静，我就喜欢这种一份配置一直使用的wm。最大的遗憾就是没能找回原来用的rsa密钥对，也就是说我的服务器连接都得重新来一遍，password-store也不能用了，几十个密码没法导出来。</p>

<p>从周日开始一知道今天（周四），花了太多时间，上班也用的是公司的电脑，太影响效率了，不过还好一切都解决了。总结一下这场事故中学到的东西吧：</p>

<ol>
<li>数据无价，平时得定时做好数据备份工作。鉴于xfs和ext4都没有磁盘快照功能，所以只能备份文件了，btsync似乎是一个不错的选择。</li>
<li>不要把/boot和/放在一起，其实最好的分区规范应该是分为/boot, /usr, /这3块，这样就算/挂了，还能进入内核利用/usr里面的软件来修复自身。</li>
<li>btrfs最近2年都不会再去碰了，虽然有很多很新的特性，但是一个礼拜伤我2次，这份大仇2年内都不能忘记。</li>
<li>配置文件非常重要，最好是保存在网上，之前仅仅star了一下prelude的配置导致后面很多本地的自定义都没有提交到自己的仓库，分区崩溃之后自己写的代码都没了。</li>
<li>最后再赞美一下xmonad，这是我用过的最好的桌面了。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use-orgmode]]></title>
    <link href="http://blog.joxy.org/blog/2015/03/15/use-orgmode/"/>
    <updated>2015-03-15T00:58:56+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/03/15/use-orgmode</id>
    <content type="html"><![CDATA[<p>最近看书学习感觉非常没有劲，究其原因感觉是缺少一个做笔记的工具，原来那支跟随我4年的钢笔放家里没有带过来，
京东上预订的lamy也还没有到货，看书不动笔我是什么都记不住的，所以感觉学习效率低了很多。印象笔记确实不错，
配合浏览器的markdown-here扩展就能支持markdown语法了，但是缺少一个所见即所得的笔记客户端，用markdown写完
之后转换为html还是感觉不够方便，并且总是要有网才能看到和编辑笔记很不方便。gnome自带的tomboy我也尝试了，
这东西更加不好用，连markdown都不支持怎么能拿来记笔记。</p>

<p>今天反正周六闲着没事就拿起了orgmode的<a href="http://orgmode.org/org.html">手册</a> 来看，看了几页竟然发现org转md是这么方便，果断以后就用emacs来
记笔记了，又学会一个新技能。</p>

<ul>
<li>下面就来讲讲org做笔记的基本用法吧:

<ol>
<li>使用星号来表明段落的层级，和md的使用#差不多的概念</li>
<li>支持有序列表，无序列表，语法和md类似，org或自动缩进对其每个列表项，如果发现不匹配了那就肯定某个地方缩进出问题了</li>
<li>插入链接\[[链接]\[名字]] 这样就能插入一条链接了</li>
<li>用\\来断行，这样就不必要把一段话写在一行了</li>
<li>C-c C-e m m 来导出markdown文件</li>
</ol>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Emacs自定义grep-find的模板]]></title>
    <link href="http://blog.joxy.org/blog/2015/03/07/emacs-grep-find/"/>
    <updated>2015-03-07T22:40:19+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/03/07/emacs-grep-find</id>
    <content type="html"><![CDATA[<p>被emacs的搜索功能纠结好久了，今天下定决心来解决一下。以前执行<code>grep-find</code>命令的时候查找的模板都是<code>find . -type f -exec grep -nH -e {} +</code>，但是这条命令在fish下没法用，找了一下发现在<a href="https://github.com/fish-shell/fish-shell/issues/95">这个issue</a>里面作者提到了为什么fish里面没法用find，因为在fish里面<code>{}</code>是有意义的，所以就会提示exec缺少参数，所以如果写成<code>find . -type f -exec grep -nH -e '{}' +</code>就可以了，接下来的任务就是修改emacs的配置，把默认的<code>grep-find</code>的行为改掉。</p>

<p>因为查找功能是emacs默认就有的，所以我直接就去源代码目录找了，在<code>/usr/share/emacs/24.4/</code>下执行<code>grep 'grep-find' -R *</code>，然后在<code>lisp/ldefs-boot.el</code>和<code>lisp/loaddefs.el</code>找到了相关的代码，然后试着修改第12669行，这行看起来像是相关的代码，结果改完了半天不生效，无奈之下去<a href="http://stackoverflow.com/questions/28915372/change-the-default-find-grep-command-in-emacs/">stackoverflow</a>提问，这个网站效率真的不是一般的高，很快就拿到答案了，有人说我找到的代码只不过是docstring而已，要修改的话得改<code>grep-find-template</code>,通过<code>C-h v</code>查看了一下这个变量的值，默认的是<code>"find . &lt;X&gt; -type f &lt;F&gt; -exec grep &lt;C&gt; -nH -e &lt;R&gt; {} +"</code>，修改它就行了，编辑<code>~/.emacs.d/personal/custom.el</code>，在最底下加上<code>(setq grep-find-template "find . &lt;X&gt; -type f &lt;F&gt; -exec grep &lt;C&gt; -nH -e &lt;R&gt; \'{}\' +")</code>，然后<code>eval-buffer</code>，问题完美解决，不得不说emacs真是灵活，不用改源代码就能实现自定义功能。</p>

<p>后面又修改了<code>find-grep-dired</code>的模板，好像这条命令没有模板，所以我直接改的代码，<code>/usr/share/emacs/24.4/lisp/find-dired.el.gz</code>编辑第278行，把{}转义了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[学习emacs-eww]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/28/emacs-eww/"/>
    <updated>2015-01-28T22:50:06+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/28/emacs-eww</id>
    <content type="html"><![CDATA[<p>最近一段时间比较无聊，<a href="http://www.iyue.club">http://www.iyue.club</a>一直没有去维护了，目标不明确，不知道奋斗目标。
而且工作的事比较无聊，不断的重构原有的代码，想着怎么尽量把代码写短写优化，接触的新东西也不多，这么久没有学习新东西都让我感到深深的危机感了。</p>

<p>目前的计划还是慢慢来学习ruby on rails，所以空闲时间就做点有意思的事情了。现在来记录一下eww的用法，以后便于查阅，熟能生巧。eww的文档可以通过emacs自身来查看，现在就来总结一下emacs文档里对eww的介绍，我都是通过<code>C-h r</code>来打开emacs自带的info然后查找到eww的章节然后开始看的。</p>

<p>基本操作：</p>

<ol>
<li><code>M-x eww RET</code>输入url或者关键字，就可以打开url或者用内建的dockdockgo来搜索。</li>
<li><code>l</code> 回到上一个页面，回退。</li>
<li><code>r</code> 回到下一个页面，回进。</li>
<li><code>d</code> 下载当前链接，默认保存在<code>~/Downloads</code>，这个快捷键对于下载图片很方便。</li>
<li><code>g</code> 刷新当前页面。</li>
<li><code>w</code> 复制当前url到剪切板。</li>
<li><code>H</code> 查看历史记录。</li>
<li><code>b</code> 添加书签。</li>
<li><code>B</code> 查看书签。</li>
<li><code>&amp;</code> 调用外部浏览器打开当前url。</li>
<li><code>v</code> 查看当前页面源码，如果安装了html-mode就会用html-mode来渲染。</li>
<li><code>C</code> 查看所有存在的cookie</li>
</ol>


<p>上面这些东西都可以查看文档得到，比较没有营养，还是学习新东西有意思。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用btsync]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/20/use-btsync/"/>
    <updated>2015-01-20T18:18:25+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/20/use-btsync</id>
    <content type="html"><![CDATA[<p><meta charset="UTF-8"/>
昨天从<a href="http://program-think.blogspot.com/">编程随想</a>的博客上知道了<a href="https://www.getsync.com/">btsync</a>这个东西，用来p2p分享文件很是方便，所以我也尝试了一下，配置很简单，我在自己的笔记本和公司电脑都装好了，这样上班的时候2台电脑同步文件就方便了。</p>

<p>但是遇到了一个有点麻烦的问题，在最初我能够脸上p2p网络，并且找到了供源的机器，但是就是没法和他们同步，总是提示和另一方时间偏差太大无法同步，搜了一下发现是系统时间设置的问题，通过<a href="https://wiki.archlinux.org/index.php/Time">wiki</a>又好好了解了一下linux的时间机制。</p>

<p>linux上的时间包括2种，一是硬件时间，另一个是系统时间。</p>

<ol>
<li><p>硬件时间：(Real Time Clock, RTC)是由机器硬件记录的时间，根据<a href="http://www.tldp.org/LDP/sag/html/hw-sw-clocks.html">tldp</a>的说法，个人电脑都内建了一块独立的电池，来给一个时钟供电，这个时钟可以通过BIOS来设置，或者开机之后通过操作系统来设置。</p></li>
<li><p>系统时间:(software clock)，这个时间是由linux内核来设置的。在系统中存放着一个叫做<code>/etc/adjtime</code>的配置文件，我本机这个文件是7月份创建的，也就是我上次重装系统的时间，是linux的初始系统时间，之后linux估计用了某种还不清楚的手段，每次开机都会更新最新的系统时间。</p></li>
</ol>


<p>我的问题就是系统时间和硬件时间不一致，估计是因为双系统和windows共存导致的，解决方法就是通过执行<code>sudo hwclock --systz</code>来把系统时间和硬件时间都和本地时区的时间对齐。时区配置文件是<code>/etc/localtime</code>这个文件可以通过<code>timedatectl</code>命令来设置，也可以手动建立到<code>/usr/share/zoneinfo/Asia/Hong_Kong</code>的软链接，或者是直接复制<code>/usr/share/zoneinfo/Hong_Kong</code>到<code>/etc/localtime</code>来设置。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python2编码问题]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/13/python-encoding/"/>
    <updated>2015-01-13T08:06:21+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/13/python-encoding</id>
    <content type="html"><![CDATA[<p>这篇文章是要记录今天写一个采集是遇到的编码问题的，但是因为在写博客时遇到了一些问题，所以也就顺便记录一下。</p>

<p>在执行rake new_post的时候，突然提示</p>

<pre>
rake aborted!
LoadError: cannot load such file -- bundler/setup
/home/joey/octopress/Rakefile:2:in `<top (required)>'
(See full trace by running task with --trace)
</pre>


<p>突然感觉很奇怪，前几天更新博客的时候都没有遇到这种情况，后来执行<code>rake --trace</code>的时候发现</p>

<pre>
/usr/lib/ruby/2.2.0/rubygems/core_ext/kernel_require.rb:54:in `require'
/usr/lib/ruby/2.2.0/rubygems/core_ext/kernel_require.rb:54:in `require'
/home/joey/octopress/Rakefile:2:in `<top (required)>'
/usr/lib/ruby/2.2.0/rake/rake_module.rb:28:in `load'
/usr/lib/ruby/2.2.0/rake/rake_module.rb:28:in `load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:689:in `raw_load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:94:in `block in load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:176:in `standard_exception_handling'
/usr/lib/ruby/2.2.0/rake/application.rb:93:in `load_rakefile'
/usr/lib/ruby/2.2.0/rake/application.rb:77:in `block in run'
/usr/lib/ruby/2.2.0/rake/application.rb:176:in `standard_exception_handling'
/usr/lib/ruby/2.2.0/rake/application.rb:75:in `run'
/usr/bin/rake:33:in `<main>'
</pre>


<p>原来是系统ruby的版本更新到2.2了，以前是2.1的，octopress用的是2.1的gem，也许是和2.2的ruby不兼容吧，所以要重装2.2的gem套系，执行<code>proxychains gem install bundle</code>，有经验了必须要通过代理才能访问rubygem网站，下载完之后需要把<code>/home/joey/.gem/ruby/2.2.0/bin</code> 添加到环境变量中，因为我用的是fish，所以编辑<code>~/.config/fish/config.fish</code>就行了。然后用bundle安装完必要的依赖<code>proxychains bundle install</code>，下载一大堆gem，最后发现系统用的rake已经是10.4.2版的了，而配置文件中需要的还是10.4.0,手动编辑一下<code>Gemfile.lock</code>，把版本号改过来就行了，后来又重装了一下<code>safe_yaml</code>和<code>liquid</code>，把对应的版本号也都改过来了，一个小版本升级搞得这么麻烦，真是郁闷。</p>

<p>接下来就是说说今天写代码遇到的问题了。</p>

<p>需求很简单（话说写采集需求都很明确），这回需要的是采集明星的信息，第一个方案用的是采集baidu整理的明星信息，过程很简单，写了一个简单的脚本采了900条数据，但是后来发现图片做了防盗链，采集过来的图片不是图片的绝对路径，而是通过一台服务器生成的图片，也许是做了cookie的限制或者是做了ip的限制，导致每次刷新页面的时候都会返回一个403错误，链接在<a href="http://www.baidu.com/s?wd=%E6%98%8E%E6%98%9F%E5%A4%A7%E5%85%A8&amp;rsv_spt=1&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=4&amp;rsv_sug4=83&amp;rsv_sug1=3&amp;rsv_pq=d5fdf7cd00002ac7&amp;rsv_t=975c0jUWTeYgIUYA%2FfdqSJ75f%2BipUP9QR9v8Qgqb2jzy3rnHgTU3k4rBD%2B5moP73i00p&amp;rsv_sug2=0&amp;inputT=5564">这里</a>，以后有时间也许会去看看这个防盗链的实现，但是现在我可懒得花时间去研究怎么破解这个限制，那就换别的站采集吧。</p>

<p>和产品沟通了一下，他也觉得如果死扣baidu是不明智的选择，后来换成360整理的资源了，链接在<a href="http://www.haosou.com/s?ie=utf-8&amp;shb=1&amp;src=360sou_newhome&amp;q=%E6%98%8E%E6%98%9F%E5%A4%A7%E5%85%A8">这里</a>，数据也比较明确，分成3栏：领域，地域，性别，这个分类还是比较好的，以后我们拿来查询也方便。通过chrome开发工具，找到了js的接口，简单分析了一下就知道要获取那块数据，接下来就是敲代码了，最后的代码在<a href="https://gist.github.com/xcaptain/cbf9980f1b30b2467d8a">这里</a>，本来是打算试试octopress对于gist的支持的，但是因为gist在国内被墙了，会影响整篇文章的阅读，所以就换个链接在这里，有兴趣的朋友就去看看。</p>

<p>在写代码过程中遇到一个编码问题，困扰我很久，不过最终还是解决了。</p>

<p>在使用python2的时候，要自己手动设置编码，python默认的字符串编码是ascii，这就导致如果在python2程序中出现了中文都会提示一个语法错误，但是如果在python2文件中强制加上一句<code># -*- coding: utf-8 -*-</code> 这样python在执行程序的时候就知道使用utf-8来编码里面的字符串了。也许是我本地locale的设置，在打开python解释器的时候总是会自动帮我使用utf-8编码。
首先说说ascii编码，ascii只能编码代码点从0到127的字符，也就是英文字符，如果遇到代码点很高的字符，比如说中文，就没法争取的编码了，就会报错。下面来举几个例子：</p>

<pre><code class="python2">s1 = '你好，world' #这里如果指定了文件的编码为utf-8，会自动把这个字符串编码成utf-8
s1 =&gt; '\xe4\xbd\xa0\xe5\xa5\xbd\xef\xbc\x8cworld'
s2 = u'你好，world' #这里前面加了一个u来表明这个字符串是一个unicode字符串
s2 =&gt; u'\u4f60\u597d\uff0cworld'
u2 = s2.encode('utf-8')
u2 =&gt; '\xe4\xbd\xa0\xe5\xa5\xbd\xef\xbc\x8cworld'
</code></pre>

<p>字符串在内存中应该是用类似utf-8的形式存储的，这样比较节省内存空间，而且也不会出现太多的0导致字符串在大尾和小尾机器上的不兼容。所以对于一个python字符串的旅程可以大致归结为：</p>

<ol>
<li>在编辑器里写下<code>s1 = '你好，world'</code>然后保存为一个python文件的时候，编辑器会自动选择某种编码来保存这个文件，一般来说都是用的utf-8。</li>
<li>python把这个程序加载进解释器的时候，会根据文件头来判断使用什么编码来解码这个文件，也就是<code># -*-coding: utf-8 -*-</code>这行，如果没有这行就会用默认的<code>ascii</code>来解码。</li>
<li>这时候程序里的字符串都是utf8的。
写到这里突然发现昨晚的问题实在不算问题，看来之前是没有静下心来研究，写博客还是有好处的。</li>
</ol>


<p>接下来再看看python3,python3的默认编码是unicode，而实际存在内存中的就是字节码，bytecode。也就是说一个字符串只有2种状态，unicode和byte，这样就节省很多事情了，没有各种编码解码的麻烦。
<code>python3
s = '你好，world' #这是一个str类型的字符串
b1 = s.encode('utf-8') #这是把s编码为utf-8后的字节码
b2 = s.encode('gbk') #把s编码为gbk后的字节码
</code>
相对于2来说，3最大的进步就是不需要手动encode，decode，对于处理未知编码的文件最方便了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[玩弄git]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/06/play-with-git/"/>
    <updated>2015-01-06T06:54:11+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/06/play-with-git</id>
    <content type="html"><![CDATA[<p>经过元旦几天的努力，论坛正式上线了<a href="http://f.joxy.org">http://f.joxy.org</a>，目前仅仅是使用了<a href="https://github.com/discourse/discourse">discourse</a>的框架，自己还没有开始定制，总是需要一个熟悉的过程的，本地的开发环境因为邮件的问题，现在还没有好，挺郁闷的。</p>

<p>今晚就稍微熟悉了一下discourse的结构。</p>

<ol>
<li>我本地的开发环境，这个没什么多说的，就是用vagrant跑了一个虚拟机，上面运行着discourse需要的环境。</li>
<li>线上的环境是用docker运行的，这是官方推荐的安装方式，说实话最初我竟然没有明白discourse的架构。</li>
</ol>


<p>其实也是很简单的，在我的vps上跑着一个docker，docker类似于一个虚拟机，创建了一个容器，里面跑着discourse需要的环境。代码存放在<code>/var/www/discourse</code>下，但是因为是用官方的安装方法安装的，只能等官方的更新，如果我们要自定义怎么办呢？那就需要改git的配置了。</p>

<p>我在github上面fork了官方的仓库，把这个自己的仓库拷贝到本地，改了一些简单的文件，提交，这时候我去官方仓库看，发现他们竟然领先我好多个版本，那就 把他们的改动也拿过来吧，这里需要添加官方仓库的配置，使用<code>git remote add upstream git://github.com/discourse/discourse.git</code>，这时候会发现在<code>.git/config</code>里面多了一个remote的配置，如果需要把这个upstream的改动也合并到自己的仓库，就要<code>git fetch upstream</code>，等改动都更新下来了之后会存放在<code>.git</code>目录下，这时候代码还没有变化。如果执行<code>git pull upstream master</code>，就能把版本库中的版本检出到主分支了。然后执行<code>git push origin master</code>就能把本地的版本更新到github了。</p>

<p>我想把改动也更新到vps上，那就需要改vps上git仓库的配置了。</p>

<ol>
<li><p><code>cd /var/discourse/</code>
切换到docker配置所在的目录</p></li>
<li><p><code>./launcher ssh app</code>
因为我当初初始化配置的时候用的是app来作为container的名字，所以要加上app参数</p></li>
<li><p><code>cd /var/www/discourse/</code></p></li>
<li><p><code>git remote add develop git://github.com/xcaptain/discourse.git</code>
这样就把我的github仓库中的版本作为开发版加入到线上的配置了。</p></li>
<li><p><code>git pull develop master</code>
 就能把我的版本拿下来了，因为我的这个版本都会现在本地开发环境测试过之后再上，所以是很安全的</p></li>
</ol>


<p>这样应该也算是和一大伙志愿者协同开发吧，虽然我没有提交pull request，但是我一直在用别人的免费的代码，真是惭愧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[调试shadowsocks]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/04/debug-shadowsocks/"/>
    <updated>2015-01-04T07:16:58+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/04/debug-shadowsocks</id>
    <content type="html"><![CDATA[<p>昨天把在东京的虚拟机搬到加州去了，感觉这次搬家还是很值得的，传输稳定了很多，原来在东京的时候看个youtube经常卡，但是现在看youtube很流畅，不过每月多给2美元，让我帐号里的钱花得更快了。原来装的是freebsd10的系统，现在我把系统换成ubuntu14.04了，因为bsd的软件还是比较老的，而ubuntu就新多了，而且docker和container等都得在linux才能跑。</p>

<p>系统安装完之后肯定是要部署shadowsocks的，操作很简单就不多说了，一点问题都没有，但是今天早上起床开机就发现没法翻墙了，这时候问题就出现了，耽误我一整天时间。</p>

<p>笔记本没法翻墙是什么问题呢？试了一下手机，用fqrouter是没问题的，那就说明服务器端是没问题的，好吧，在客户端上找原因。</p>

<p>之前安装的客户端是nodejs版的，一直都这么用感觉没什么问题，现在我就打算换个客户端版本，试试python的。安装也很简单，但是就是上不了网，真是郁闷。没办法了，慢慢来调试找问题吧。我在服务器端和客户端都开启了-v参数，用来详细输出日志。</p>

<ol>
<li><p>用fqrouter访问的时候，服务器端输出：
 <pre>
 2015-01-03 08:48:07 INFO: accept a connection.
 2015-01-03 08:48:07 INFO: connect to: 106.162.216.94:443
 2015-01-03 08:48:07 INFO: asyncns resolved.
 2015-01-03 08:48:07 INFO: remote connected.
 </pre>
 看来这是正常连接，返回数据也正常。</p></li>
<li><p>本地用firefox访问google，服务器端输出：
 <pre>
 2015-01-03 08:49:56 INFO: accept a connection.
 2015-01-03 08:49:56 INFO: connect to: plus.google.com:443
 2015-01-03 08:50:16 INFO: asyncns resolved.
 2015-01-03 08:50:16 ERROR: getaddrinfo: Operation now in progress
 2015-01-03 08:50:16 INFO: current server connection: 2
 </pre>
 这就是失败的连接在服务器的日志了，只看到一行错误，搞不懂原因。</p></li>
<li><p>在服务器端执行<code>netstat -naltp | grep 8388</code>的输出：
 <pre>
 tcp        0      0 111.222.231.123:8388    0.0.0.0:*               LISTEN      1738/ss-server
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29403     ESTABLISHED 1738/ss-server
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29406     ESTABLISHED 1738/ss-server
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29402     TIME_WAIT   -
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29400     TIME_WAIT   -
 tcp        0      0 111.222.231.123:8388    152.42.49.117:29401     TIME_WAIT   -
 </pre>
 本地可以连接服务器的端口，那为什么没有数据返回呢？</p></li>
<li><p>在本地执行<code>netstat -naltp | grep 1080</code>的输出：
 <pre>
 tcp        0      0 127.0.0.1:1080          0.0.0.0:*               LISTEN      732/python
 tcp        0      0 127.0.0.1:45312         127.0.0.1:1080          ESTABLISHED 744/firefox
 tcp        0      0 127.0.0.1:1080          127.0.0.1:45312         ESTABLISHED 732/python
 tcp        0      0 127.0.0.1:1080          127.0.0.1:45307         TIME_WAIT   -
 tcp        0      0 127.0.0.1:1080          127.0.0.1:45309         TIME_WAIT   -
 </pre>
 看来浏览器和本地端口之间也是通的。</p></li>
</ol>


<p>本地应用可以连接本地的端口，本地的端口可以连接服务器，为什么就是没有数据呢？不会调试web程序，不会抓包，这时候只能乱猜原因，一下午都没有想通问题，就在我想要发帖求助的时候，想了一下为什么用fqrouter的时候服务器端接收到的是一个ip，而本地客户端连接服务器的时候就是一个域名，也许dns出问题了，试了一下<code>ping www.google.com</code>，果然不通，问题找到了，虚拟机提供商这个机房的dns昨晚出问题了，导致解析失败，添加一个第三方的dns，问题解决。</p>

<p><code>vi /etc/resolvconf/resolv.conf.d/base</code>添加下面2行</p>

<pre>
nameserver 8.8.8.8
nameserver 8.8.4.4
</pre>


<p>然后执行<code>resolvconf -u</code>刷新dns，这样就能使用google的dns了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[部署邮件服务]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/03/deploy-email-service/"/>
    <updated>2015-01-03T08:43:43+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/03/deploy-email-service</id>
    <content type="html"><![CDATA[<p>今天打算研究一下搭建自己的mail server用来收发邮件，不过后来发现在自己服务器上部署邮件服务太麻烦了，没有那么高性能的服务器，而且额外开放的服务可能会被黑客利用，那么就采用第三方的邮件服务吧。</p>

<h4>首先确定一下发件服务。</h4>

<p>根据网上的推荐，我用的是<a href="https://mandrillapp.com/">mandril</a>，这家公司为免费帐号提供每月发12000封邮件，对于个人玩来说足够了。接下来就是注册帐号，注册完成之后会有一个向导引导着去配置发件服务。填好之后配置都会出现在<a href="https://mandrillapp.com/settings">这里</a>，这些配置包括发件服务器的域名，端口，smtp用户名，以及密码，密码是网站生成的，要好好保存。</p>

<h4>然后就是配置收件服务</h4>

<p>同样也是根据网上的推荐，收件服务用的是国内一家公司的，叫做<a href="https://www.zoho.com/">zoho</a>，这家公司为每个免费帐号提供一个代收域名，15个免费邮箱，每个免费邮箱提供5G存储空间，对于个人玩来说也是足够了的，因为可以把邮件下载到本地，然后删除服务器上的邮件存档，所以这5G的空间可以永远也用不完。好像这家公司就在中关村，真想去参观一下。用zoho的原因是它提供邮件代收服务，我有一个域名<code>joxy.org</code>，我想注册一些邮箱以<code>@joxy.org</code>结尾，zoho就提供这种功能。过程也是很简单，需要先去注册帐号，注册帐号的时候要验证你是否对这个域名有所有权，所以还需要去<a href="https://mya.godaddy.com/">godaddy</a>上面验证一下，我是通过cname的形式来验证的。注册完成之后还得配置一下godaddy，因为在注册域名的时候默认设置了2个收件商，现在我不想用那2个厂商的收件服务了，所以要改改dns设置，找到mx这条配置，删掉额外的2个厂商的配置，然后加上一条mx记录，Host是@,表示joxy.org自身，Points to填mx2.zohomail.com，剩下的随便填就行了。这样当有人往<code>user@joxy.org</code>发邮件的时候，发件服务器通过dns查询的时候就知道要发给zoho，zoho就可以帮忙代收。</p>

<h4>发件服务和收件服务都配置好了，接下来就是测试一下是否能收发邮件了。</h4>

<p>用thunderbird可以很方便的写邮件收邮件。把我刚刚创建的xiefei@joxy.org这个帐号创建了，手动配置好这个帐号发送邮件和接收邮件的设置，就可以开始测试了。在配置smtp发件的时候需要输入密码验证用户是否有权限来发邮件，所以一定要记得填smtp的密码。我测试了一下和我的gamil邮箱互发邮件，一点问题都没有，而且邮件也没有进入垃圾箱。这真是太好了，图形界面的客户端可以收发邮件，真想看看通过php,ruby脚本能不能发邮件。</p>

<p>以上的配置参考了youtube上的<a href="https://www.youtube.com/watch?v=ndIflJOGSww">一个视频</a>，真感谢作者分享这么好的东西，省去了我翻资料学习的过程。</p>

<p>刚刚测试discourse的时候已经把邮件功能加上了，可以发送，真是神奇啊。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决pacman依赖关系破裂问题]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/01/arch-pacman-broken/"/>
    <updated>2015-01-01T19:35:23+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/01/arch-pacman-broken</id>
    <content type="html"><![CDATA[<p>今天准备更新一下系统，执行<code>sudo pacman -Syu</code>的时候，竟然没法同步软件源了，报告说依赖错误。</p>

<pre>
packagekit: requires pacman<4.2.0
package-query: requires pacman<4.2.0
</pre>


<p>但是我查看了一下pacman的版本,<code>pacman --version</code>发现是4.1的满足需求啊，为什么会有这样的提示呢？我想用<code>sudo pacman -S pacman</code>重装pacman也不行，真是费解，这么重要的软件可千万不能出错啊。后来上网搜了一下，发现有人也遇到这种情况，都是直接<code>sudo pacman -R packagekit python-packagekit yaourt package-query</code>，然后再<code>sudo pacman-db-upgrade</code>升级一下数据库，然后再<code>sudo pacman -Syu</code>，ok问题解决。</p>

<p>还有一点是关于virtualbox的，今天我又用了一下vagrant，发现每次<code>vagrant up</code>都会提示：</p>

<pre>
VirtualBox is complaining that the kernel module is not loaded. Please
run `VBoxManage --version` or open the VirtualBox GUI to see the error
message which should contain instructions on how to fix this error.
</pre>


<p>用最简单的方法<code>sudo modprobe vboxdrv</code>然后<code>lsmod | grep vbox</code>发现加载进了</p>

<pre>
vboxdrv               348377  3 vboxnetadp,vboxnetflt,vboxpci`
</pre>


<p>但是这时候还是会报错说找不到网卡驱动，后来我执行<code>sudo vboxreload</code>显示：</p>

<pre>
vboxpci                23139  0
vboxnetflt             27412  0
vboxnetadp             25443  0
vboxdrv               348377  3 vboxnetadp,vboxnetflt,vboxpci
</pre>


<p>这时候才算是真正的把所有的驱动都加进来了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[尝试hhvm]]></title>
    <link href="http://blog.joxy.org/blog/2015/01/01/try-hhvm/"/>
    <updated>2015-01-01T00:10:28+08:00</updated>
    <id>http://blog.joxy.org/blog/2015/01/01/try-hhvm</id>
    <content type="html"><![CDATA[<p>今天听到一个新闻说维基百科把他的php引擎由zend全面转到hhvm了，详情见<a href="https://www.mediawiki.org/wiki/HHVM">这里</a>。其实之前对于这东西是闻所未闻的，太不关注php的发展了，后来详细搜了一下，才稍微了解了一点php代码的执行过程。</p>

<p>对于动态语言来说，都是首先通过代码解析来生成字节码，然后通过解释器来执行这些字节码，php用的解释器叫作zend。看来和python差不多，程序在执行的时候也会先生成字节码，然后用python解释器去执行这些字节码。不过解释器的使用也导致了程序运行缓慢。所以现在facebook就做了一个叫作hhvm的东西，当通过hhvm来执行php程序的时候，会先生成一种中间码(intermediat byte code)也叫作HHBC(hhvm byte code)，然后hhvm会通过一种即时编译(just in time)的技术，将这种中间码编译为本地可执行的x86-64机器码，最后执行代码的时候等于是本地执行一个可执行程序，效率自然比解释器高了很多。不知道有没有什么方式能够把hhvm的这些步骤分离出来分析，真想看看php的字节码长什么样，生成的二进制程序长什么样。</p>

<p>我在本地立刻部署了一下HHVM的环境，很简单<code>sudo pacman -S hhvm</code>直接就安装hhvm了，测试一下效果，随便写一个php文件，然后<code>hhvm test.php</code>如果安装成功的话就可以得到像执行<code>php test.php</code>一样的效果，现在还没想好写个怎样的测试用例来比较hhvm和原生php的速度。</p>

<p>hhvm装好了之后当然不能只是用它来执行脚本，最重要的还是在服务器端编程上，当nginx接收到了一个请求的文件之后，并且把这个请求交个php的fastcgi处理后，在这里就不能用原生的php来执行文件里的php了，必须通过hhvm来执行，简单，就是不要启动php-fpm嘛，我看了一下安装hhvm的时候竟然自动连systemd的配置文件也生成了，所以我只要执行<code>sudo systemctl start hhvm.service</code>就能开启hhvm的监听程序了，类似php-fpm，hhvm服务器的配置文件存在<code>/etc/hhvm/server.ini</code>，在我这里配置文件写的是监听9000端口，那么<code>netstat -naltp | grep 9000</code>真的看到了一个监听的进程。然后就是确保nginx的配置文件中<code>fastcgi_pass</code>的值是<code>127.0.0.1:9000</code>，这样所有进入9000端口的数据都会被hhvm所处理。随便写了一个简单的数据库查询示例，暂时没发现hhvm和原生php的性能区别，也许是测试代码写得不好。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[采集一个论坛的帖子来进行数据分析]]></title>
    <link href="http://blog.joxy.org/blog/2014/12/31/web-crawl-again/"/>
    <updated>2014-12-31T07:49:40+08:00</updated>
    <id>http://blog.joxy.org/blog/2014/12/31/web-crawl-again</id>
    <content type="html"><![CDATA[<p>今天接到一个小小的需求，又是和采集相关的，我都要烦死了，采集这东西写得都要腻了。</p>

<p>不过和以前的那些采集有点区别，不再是采集文章了，而是开始采集论坛的帖子。说实话我觉得采集论坛比较简单，因为论坛都是php的页面，页面组织布局一般不会怎么变，而新闻站基本都是cms系统生成的html静态页，静态的页面就有太多可能性了，而且不排除有的编辑太敬业把每个页面都做得不一样。</p>

<p>采集源站是<a href="http://qq.100bt.com">http://qq.100bt.com</a>，和我最近做的<a href="http://www.zeze.com">zeze</a>是同一类型的东西，而且突然发现zeze竟然借鉴了很多这个网站的元素。废话不多说，这次采集主要是为了了解哪些资讯比较受欢迎，然后我们就可以有针对性的来推广我们的内容，看起来像是在收集竞争对手的信息而实现知己知彼百战不殆，这样的活我喜欢。这个叫作百田圈圈的网站似乎运营得不错，里面积累了差不多百万的帖子，用户似乎也很活跃。</p>

<p>其实要获得的信息不多，在我设计的数据库结构中包含以下字段：</p>

<pre>
tid: 帖子的id，用来作为表的主键
url: 帖子的url，便于访问
subject: 帖子标题
author_name: 楼主名，有这个东西可以用来分析哪些用户比较活跃
replies: 帖子的回复数，这个字段是用来衡量一个帖子的受欢迎程度的最重要指标
view: 帖子被查看的次数
pubdate: 发帖时间
maxpage: 帖子页数，因为有的帖子是回复楼层的，所以如果一个帖子分了很多页说明这个帖子内容丰富
category: 帖子所属分类，用来来分析哪些大类的话题比较火
</pre>


<p>没有数据库直接操作真是麻烦，上面这些数据都得分析网页去获取，而且不是在同一个页面，需求挺麻烦的但是不难。</p>

<p>代码传到<a href="https://github.com/xcaptain/BeautifulSoup_Instance/tree/master/btqq">github</a>上面了，以前写的那些采集都是用脚本的形式来实现的，这回尝试了一下自己构造一个采集类，这时候才发现对于python的面向对象特性用的太少了，在设计类的结构，接口上面都很不熟练，现在的代码设计在python大牛严重肯定是很小儿科的，以后要多学习OOP的编程思想，不能总是一个函数一个函数这样顺序的执行下来。</p>

<p>写这么一个简单的任务竟然还花了我一天的时间，看来编码能力还是有待加强，经过总结之后发现问题主要存在三方面：</p>

<ol>
<li>对mysql的查询语句不熟悉，因为我把tid设置为了主键，所以不能重复插入，我想要实现<code>insert into on duplicate key continue</code>的功能，找了半天只看到了<code>insert into on duplicate key update</code>的语法，但是后者不是我想要的，因为使用的是python的<code>MySQLdb</code>来驱动mysql的，这东西对于原生的sql语句支持不是很好，不过幸好最后我找到了<code>insert ignore into</code>这种语句，一下解决了问题，虽然<code>MySQLdb</code>在<code>execute</code>的时候会有警告，但是毕竟实现了功能。</li>
<li><code>MySQLdb</code>这个库的使用不熟悉，在用它来执行sql语句的时候出现了很多问题，看来有时间得专门总结一下python驱动mysql的方法。</li>
</ol>


<p>今晚下班回的路上突然发现代码少写了很多异常检测，比如说没有判断网络链接失败，页面匹配为空等，真希望程序能够按照我设想的执行，等明天早上到了公司6张表都给我装得满满的，明天到了公司 再去修改代码了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[通过vagrant安装coreos]]></title>
    <link href="http://blog.joxy.org/blog/2014/12/27/install-coreos-with-vagrant/"/>
    <updated>2014-12-27T05:54:57+08:00</updated>
    <id>http://blog.joxy.org/blog/2014/12/27/install-coreos-with-vagrant</id>
    <content type="html"><![CDATA[<p>昨晚学习了一下vagrant的用法，今天开始试着用vagrant来在本地虚拟化一个coreos的系统，等熟悉coreos的基本操作之后就可以把我现在vps的freebsd10换成coreos了。</p>

<p>按照<a href="https://coreos.com/docs/running-coreos/platforms/vagrant/">官方的教程</a>一步一步来。</p>

<ol>
<li><code>git clone https://github.com/coreos/coreos-vagrant.git</code> 会在当前目录创建一个叫做<code>coreos-vagrant</code>的目录，里面包含coreos的基本配置以及vagrant的配置。</li>
<li><p>更改配置。vagrant的配置文件就是<code>Vagrantfile</code>，这是一个ruby的文件，里面定义了2个配置文件</p>

<p> CLOUD_CONFIG_PATH = File.join(File.dirname(<strong>FILE</strong>), &ldquo;user-data&rdquo;)
 CONFIG = File.join(File.dirname(<strong>FILE</strong>), &ldquo;config.rb&rdquo;)</p></li>
</ol>


<p>一个是当前目录下的<code>user-data</code>文件，一个是当前目录下的<code>config.rb</code>文件</p>

<pre>
VirtualBox is complaining that the kernel module is not loaded. Please
run `VBoxManage --version` or open the VirtualBox GUI to see the error
message which should contain instructions on how to fix this error.
</pre>


<p>根据Vagrantfile里面 提供的url下载系统的时候，可能是url被屏蔽了，所以需要使用点小手段<code>proxychains vagrant up</code></p>

<p>但是等下载都完成之后却出现下面这段错误信息</p>

<pre>
Command: ["hostonlyif", "create"]

Stderr: 0%...
Progress state: NS_ERROR_FAILURE
VBoxManage: error: Failed to create the host-only adapter
VBoxManage: error: VBoxNetAdpCtl: Error while adding new interface: failed to open /dev/vboxnetctl: No such file or directory
VBoxManage: error: Details: code NS_ERROR_FAILURE (0x80004005), component HostNetworkInterface, interface IHostNetworkInterface
VBoxManage: error: Context: "int handleCreate(HandlerArg*, int, int*)" at line 66 of file VBoxManageHostonly.cpp
</pre>


<p>听起来是virtualbox的网卡驱动没有加载进来，在网上搜到一个很简单的方法，<code>sudo vboxreload</code></p>

<p>virtualbox的驱动问题解决之后，还是执行<code>proxychains vagrant up</code>但是这回却报错了</p>

<pre>
Bringing machine 'core-01' up with 'virtualbox' provider...
Bringing machine 'core-02' up with 'virtualbox' provider...
Bringing machine 'core-03' up with 'virtualbox' provider...
==> core-01: Checking if box 'coreos-stable' is up to date...
==> core-01: Fixed port collision for 22 => 2222. Now on port 2250.
==> core-01: Clearing any previously set network interfaces...
==> core-01: Preparing network interfaces based on configuration...
    core-01: Adapter 1: nat
    core-01: Adapter 2: hostonly
==> core-01: Forwarding ports...
    core-01: 22 => 2250 (adapter 1)
==> core-01: Running 'pre-boot' VM customizations...
==> core-01: Booting VM...
==> core-01: Waiting for machine to boot. This may take a few minutes...
    core-01: SSH address: 127.0.0.1:2250
    core-01: SSH username: core
    core-01: SSH auth method: private key
    core-01: Warning: Remote connection disconnect. Retrying...
    core-01: Warning: Remote connection disconnect. Retrying...
</pre>


<p>翻墙之后127.0.0.1是vps的内部loop地址，不是本机的，所以怎么也ssh不上去，既然东西都下载完了那就不需要代理了，直接<code>vagrant up</code>就有了下面的信息，太好了，这是在自动装系统呢。</p>

<pre>
Bringing machine 'core-01' up with 'virtualbox' provider...
Bringing machine 'core-02' up with 'virtualbox' provider...
Bringing machine 'core-03' up with 'virtualbox' provider...
==> core-01: Checking if box 'coreos-stable' is up to date...
==> core-01: There was a problem while downloading the metadata for your box
==> core-01: to check for updates. This is not an error, since it is usually due
==> core-01: to temporary network problems. This is just a warning. The problem
==> core-01: encountered was:
==> core-01:
==> core-01: Failed to connect to 2404:6800:4008:c00::80: Network is unreachable
==> core-01:
==> core-01: If you want to check for box updates, verify your network connection
==> core-01: is valid and try again.
==> core-01: VirtualBox VM is already running.
==> core-02: Importing base box 'coreos-stable'...
==> core-02: Matching MAC address for NAT networking...
==> core-02: Checking if box 'coreos-stable' is up to date...
</pre>


<p>3台虚拟机全部安装ok，我有一个集群了，哈哈哈哈。查看一下集群的运行状态。</p>

<pre>
Current machine states:

core-01                   running (virtualbox)
core-02                   running (virtualbox)
core-03                   running (virtualbox)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.
</pre>


<p>查看一下virtualbox的运行状态，有3个进程分别运行着3个虚拟机。</p>

<pre>
joey     10033  1.1  0.2 163232  9492 ?        Sl   22:33   0:08 /usr/lib/virtualbox/VBoxXPCOMIPCD
joey     10040  2.6  0.4 707156 19324 ?        Sl   22:33   0:20 /usr/lib/virtualbox/VBoxSVC --auto-shutdown
joey     11184  3.8  1.9 1497696 74992 ?       Sl   22:33   0:28 /usr/lib/virtualbox/VBoxHeadless --comment coreos-vagrant_core-01_1419632903871_39166 --startvm 29a5b99b-dfa8-48e6-b18f-d63b01696df2 --vrde config
joey     11204  0.0  0.2 154828  9228 ?        S    22:33   0:00 /usr/lib/virtualbox/VBoxNetDHCP --ip-address 192.168.56.100 --lower-ip 192.168.56.101 --mac-address 08:00:27:AA:0D:77 --netmask 255.255.255.0 --network HostInterfaceNetworking-vboxnet0 --trunk-name vboxnet0 --trunk-type netflt --upper-ip 192.168.56.254
joey     27124 10.2  1.9 1527828 76788 ?       Sl   22:40   0:32 /usr/lib/virtualbox/VBoxHeadless --comment coreos-vagrant_core-02_1419633622663_70678 --startvm 07c05704-61e7-4e61-bebd-723978180348 --vrde config
joey     28280 17.8  2.0 1523732 81576 ?       Sl   22:43   0:28 /usr/lib/virtualbox/VBoxHeadless --comment coreos-vagrant_core-03_1419633784764_52573 --startvm f614df63-7556-45ac-a4ca-3654d6039d3d --vrde config
joey     29297  0.0  0.0  12384  2400 pts/2    R+   22:45   0:00 grep --color=auto -i virtualbox
</pre>


<p>再看一下我的<code>VirtualBox VMs</code>目录：</p>

<pre>
coreos-vagrant_core-01_1419632903871_39166/  coreos-vagrant_core-03_1419633784764_52573/
coreos-vagrant_core-02_1419633622663_70678/  Public_default_1419540157403_62624/
</pre>


<p>昨天还只有<code>Public_default_1419540157403_62624/</code>一个目录，今天就多了3个了，算上昨天的那个ubuntu12.04，我是不是有4个虚拟系统了？</p>

<p>进入到我的<code>Vagrantfile</code>所在的目录，执行<code>vagrant ssh core-01</code>，就登陆进我的第一个虚拟机了。</p>

<p>剩下的就是学习如何使用coreos在上面部署开发环境了，有vagrant这么方便的工具来管理虚拟机，我都不想去研究docker了，我这样一个菜鸟竟然也能管理4台机器，科技真是使人懒惰。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一次接触虚拟化]]></title>
    <link href="http://blog.joxy.org/blog/2014/12/26/learn-virtualization-1/"/>
    <updated>2014-12-26T04:27:01+08:00</updated>
    <id>http://blog.joxy.org/blog/2014/12/26/learn-virtualization-1</id>
    <content type="html"><![CDATA[<p>之前在我的vps上部署了一个<a href="http://f.joxy.org">php论坛</a>，但是后来这个框架的<a href="https://github.com/esotalk/">创始人</a>突然在github上宣布重构了<a href="https://github.com/esotalk/esoTalk">esotalk</a>的代码做了一个新的论坛框架<a href="https://github.com/flarum/core">Flarum</a>，搞得我很伤心，后来在<a href="https://en.wikipedia.org/wiki/Comparison_of_Internet_forum_software">wiki</a>上看到介绍discourse，它的作者<a href="http://www.codinghorror.com/blog">Jeff Atwood</a>说discourse是未来十年互联网论坛发展的趋势，那就搭一个来看看呗，反正以前也学过一阵子ruby on rails.</p>

<p>按照原来部署<a href="http://f.joxy.org">http://f.joxy.org</a>的模式打算先在本地部署好环境，然后提交到git server然后在线上拷贝一份代码到服务器上。但是看discourse的官方安装文档的时候发现默认是不支持在实体机上安装系统的，官方的文档只支持通过docker来部署discourse，docker久仰大名了但是就是没有用过，那好，就去见识见识呗。</p>

<p>搜索了一下发现现在比较流行的服务器环境配置，服务器管理都是通过container也就是容器来进行的，最老土的服务器管理方式是通过ssh连接上服务器，然后手动编译或者包管理的形式安装软件。但是这种方式有很大的局限性，不易把所有的机器都统一配置，因为所有配置文件都要由手动编辑，然后手动更新，必然有的机器版本早，有的机器版本晚，对于管理一个服务器集群来说这是很不方便的。而且服务器多了软件更新就是一个麻烦事，不可能一台机器一台机器的去更新。</p>

<p>目前找到了3个比较有名的虚拟化技术：</p>

<ol>
<li>docker， 更类似于chroot</li>
<li>vagrant，用来管理virtualbox虚拟机</li>
<li>rocket，暂时没什么太多了解</li>
</ol>


<p>早上出门的时候在youtube上看了一个通过docker来安装coreos的视频，但是感觉要学习yaml语法配置，比较繁琐，那就先来看看vagrant吧。</p>

<p>在vagrant的<a href="http://docs.vagrantup.com/v2/getting-started/index.html">官方文档</a>上找到了简单的使用方法，其实说白了就是一个自动安装运行virtualbox的脚本。首先得安装vagrant，<code>sudo pacman -S vagrant</code>，然后得安装virtualbox，<code>sudo pacman -S virtualbox</code>，然后还得安装一大堆的依赖，<code>sudo pacman -S virtualbox-host-modules</code>是用来安装virtualbox用来和宿主机通信的模块，如果这个软件太老了就会无法正常使用vagrant，那么一个补救措施就是<code>sudo pacman -S virtualbox-host-dkms</code>，virtualbox安装好了之后还得解决一些内核的驱动，最简单的就是<code>sudo dkms autoinstall</code>，这个命令会自动搜索<code>linux-headers</code>然后编译对应的驱动，如果系统上没有装<code>linux-header</code>那么还是会报错的，那就得<code>sudo pacman -S linux-headers</code>。需要安装的软件，驱动，都装好了之后就是在内核加载virtualbox的驱动了，很简单<code>sudo modprobe vboxdrv</code>，这时候就大功告成了。</p>

<p>对照着教程在自己的笔记本上一步一步的做，先<code>vagrant init hashicorp/precise32</code>，这回在当前的目录下创建一个叫作<code>Vagrantfile</code>的文件，这里面包含了一大堆虚拟机的配置信息。然后<code>vagrant up</code>就会启动虚拟机，这时候<code>ps aux | grep -i virtualbox</code>就会发现virtualbox已经自动在运行了，在家目录的<code>VirtualBox\ VMs/</code>目录下也会创建对应虚拟机的目录，但是没有启动那个讨厌的图形界面这很不错。因为vagrant主要是用来配置服务器的，所以不需要图形界面，等系统下载安装好了之后就可以执行<code>vagrant up</code>来启动虚拟机了，这个操作会检测是否有<code>Vagrantfile</code>里面写的系统，如果没有就会自动从网上下载。系统下完之后<code>vagrant ssh</code>可以远程连接上虚拟机，发现虚拟机上面有一个网卡ip是<code>10.0.2.15</code>，好奇怪的东西，联网方式是NAT还是bridge呢？有一个自动安装系统的脚本，叫作<code>postinstall.sh</code>，以root身份执行它会自动安装系统，等最后跑完的时候吓我一大跳</p>

<pre><code>++ rm -f '/home/vagrant/*.iso' /home/vagrant/postinstall.sh
++ dd if=/dev/zero of=/EMPTY bs=1M
dd: writing `/EMPTY': No space left on device
78697+0 records in
78696+0 records out
82518818816 bytes (83 GB) copied, 207.558 s, 398 MB/s
++ rm -f /EMPTY
++ exit
</code></pre>

<p>一下dd我83G的硬盘，这可是我整个宿主机所有的空间了，不会影响到我吧，后来<code>df -h</code>了一下才发现虚拟机没有使用多少硬盘空间，而且宿主机也没有消耗掉很多硬盘空间。这样就有了一台虚拟机了，这可比直接用virtualbox方便多了，没有预先问我分配多少颗CPU，没有问我分配多少RAM，没有问我分配多少硬盘就把系统装好了，我喜欢。</p>

<p>vagrant有一个共享目录就是宿主机的<code>Vagrantfile</code>所在的那个目录，也是虚拟机的<code>/vagrant</code>目录，这个目录双方都可以读写，想想真是有点小激动，要是以后我虚拟一个windows出来在上面跑一个qq，然后今天志军通过qq传给我的《刺杀金正恩》就不用在windows上跑着vlc服务器给我的arch笔记本供源了，不知道有没有人为vagrant做windows的box。</p>

<p>不过vagrant毕竟是建立在virtualbox之上的，虽然说虚拟机占用宿主机的资源少了，但是还可以做得更好，要让机器资源更加充分的利用就得学习docker了，加油。</p>

<p>另外今天和小青谈了一下学习方式的问题，他说我三天打鱼两天晒网没有持之以恒的做一件事，想想也确实是这样，从工作开始学习和使用php来干活，python是原来就会的所以也就没有怎么学，但是又学了几个礼拜ruby，学了几个礼拜haskell，工作在二次开发discuz，但是业余时间却自己搭了一个esotalk的论坛，现在又在研究虚拟化技术。虽然我一直认为身为一个互联网从业者就得把握住互联网的发展方向，不断学习最新的技术，我们生活在一个很开放的社会，最新最热的技术都是开源的有详细的文档，如果不去学习不去研究而是抱着把会的东西研究透彻的话，我有种辜负了这个时代的感觉。希望时代别辜负了我。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何使用emacs]]></title>
    <link href="http://blog.joxy.org/blog/2014/12/20/how-to-use-emacs/"/>
    <updated>2014-12-20T19:44:35+08:00</updated>
    <id>http://blog.joxy.org/blog/2014/12/20/how-to-use-emacs</id>
    <content type="html"><![CDATA[<p>今天闲着没事，又上我们的<a href="https://github.com/ncuopen">ncuopen</a>上面看了一下，发现小组现在活动极其不频繁，首页和wiki都没有怎么更新，然后上irc上看了一下，发现也没有人在线。</p>

<blockquote><p>一个开源社区最大的悲哀就是没有活跃的用户，没有一个持续贡献的志愿者团队。</p></blockquote>

<p>加入小组这么久了都没有做什么贡献真是惭愧，今天想了一下我可以整理一下我对于emacs使用的一点小小的心得。以下将会简单的说说我平时使用emacs来干什么。</p>

<ol>
<li>写代码，这是最基本的功能。</li>
<li>上网，在emacs24之前的版本必须使用一个叫做<code>emacs-w3m</code>的第三方扩展才能在emacs里面上网，但是现在emacs自己做了一个基于elisp写的文本浏览器<code>eww</code>，使用方式也很简单，直接<code>M-x eww</code>然后输入要搜索的内容或者是要打开的url就行，现在<code>eww</code>默认的搜索引擎是<code>duckduckgo</code>。</li>
<li>聊天，今天上<code>#ncuopen</code>上看了一下，发现聊天室里面没人在，突然比较一下那些比较火的聊天室，如<code>ubuntu</code>, <code>debian</code>每天上去都会有一大堆人在线，随便说一句话就会被别人刷屏，差距真的很大。如果要在emacs里面使用irc聊天，可以使用<code>erc</code>来连接服务器。</li>
<li>看pdf，emacs内建是可以打开pdf文件的，如果习惯了emacs的快捷键，而且不喜欢在<code>evince</code>，<code>okular</code>下面必须使用鼠标的操作，那么可以试试用emacs看pdf。</li>
<li>写博客，我自己也在github上面搭了一个octopress的博客，在本地就是用emacs编辑的博客，因为emacs支持<code>markdown</code>语法，编辑的时候可以直接看到语法高亮，保存后可以在本地预览。</li>
<li>执行shell命令，要么是使用<code>M-x shell</code>来打开一个shell或者是<code>M-x eshell</code>来使用emacs自带的终端模拟器，我喜欢用后者，然后就可以运行任何的shell命令了。不过我用eshell用得少，平时都是在<code>urxvt</code>里面执行命令的。</li>
<li>执行解释器，很动语言都内建了一个elpa的解释器，如ruby, python, php, haskell，sml等，如果想尝试一下某个表达式或者是某个代码段又不想写一个测试文件，那么在解释器里运行是最方便的了，执行<code>M-x run-python</code>, <code>M-x run-haskell</code>，会打开对应语言的解释器，就像在终端执行一样。如果想获得更多语言的支持，可以去<a href="http://elpa.gnu.org/packages/">elpa</a>或者是<a href="http://melpa.org/">melpa</a>上面找找。</li>
<li>使用git，emacs有个扩展叫做<code>magit</code>，用它来提交代码，查看差异，查看版本比在终端使用git命令方便。</li>
<li>看图，这个功能估计很少人会用，<code>display</code>和<code>feh</code>已经做得很棒了。</li>
</ol>


<p>如果要使用上面的功能，最好使用<a href="https://github.com/bbatsov/prelude">prelude-emacs</a>上面的配置，省去很多配置的麻烦。</p>

<p>另外我发现现在小组没有一个好的交流的地方，在github上面提issue总是不太方便，找到了一个开源项目<a href="https://github.com/esotalk/esoTalk">esotalk</a>可以很方便的用来搭建论坛，不知道有没有小伙伴愿意贡献一下。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[又是一个采集]]></title>
    <link href="http://blog.joxy.org/blog/2014/12/08/learn-beautifulsoup/"/>
    <updated>2014-12-08T06:25:45+08:00</updated>
    <id>http://blog.joxy.org/blog/2014/12/08/learn-beautifulsoup</id>
    <content type="html"><![CDATA[<p>前几天看到有个同事在采集<a href="https://yande.re">这个</a>站，要把上面的图片都搞下来。看他很得意的样子，似乎采集是个什么很复杂东西，其实简单得很，没什么技术含量在里面。他用的是一个叫做scrapy的采集框架，这个框架我没用过，但是自己写采集也简单。</p>

<p>之前采集过多玩和178的一些文章，需求还比较复杂，需要把ajax的接口也给搞定掉，还得把所有图片都本地化，那时候用的是urllib2+beautifulsoup这个东西采集的。</p>

<p>今天闲着没事，打算再来搞个采集玩玩，<a href="https://yande.re">yande</a>上面的图片质量还是比较高的。还是使用老一套，不过这回我不打算使用urllib2了，这东西太弱了，编码问题总是会出现，搞得我莫名其妙的，实在是打算放弃urllib2了，上网搜一下，找到了一个叫做<code>requests</code>的网络库，这个东西目前开发还是蛮活跃的，而且口气比较大，直接在官网说urllib2的api很混乱，那就是它了。页面分析的库还是用回beautifulsoup，这么久了仍然是很不喜欢写正则，所以拿这个库来解析html还是比较顺手。至于信息入库，我用的是<code>MySQLdb</code>这个库来驱动mysql，似乎这个库也比较弱，反正我是遇到很多很简单的sql语句都报错的情况了，在网上搜了一下，发现别的第三方的mysql库也很多，但是还没有下定决心换。</p>

<p>代码的思路很简单，和以前写的采集脚本差不多，都是先采集列表页，获得文章页的url，然后在文章页中采集想要的信息。信息采集完了就是入库，到这里采集过程就结束了。</p>

<p>代码很简单，已经提交到<a href="https://github.com/xcaptain/yande">github</a>了，和之前写的脚本比起来，多增加了一些东西：
1. 模糊匹配，比如说<code>soup.find(href=re.compile('user\/show'))</code>这样的东西。
2. 断点续踩，程序在跑的时候如果按下<code>Ctrl-C</code>来终止它的话，会把当前采集到的页码写入到一个叫做<code>config.py</code>的文件。
3. 异常处理，以前写的几个采集使用了很多if语句，很多嵌套的判断，就是为了人为规避异常，尽量让程序跑的时候都不遇到异常，这种写法真是太折磨人了，看到三四层嵌套判断我的头都要大了。这回尝试了一下直接在<code>try</code>里面执行代码段，如果遇到可能会有的异常就直接<code>except</code>上处理了它，真是省了很多心呀。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[入手一台二手PC]]></title>
    <link href="http://blog.joxy.org/blog/2014/11/24/got-an-old-pc/"/>
    <updated>2014-11-24T05:09:30+08:00</updated>
    <id>http://blog.joxy.org/blog/2014/11/24/got-an-old-pc</id>
    <content type="html"><![CDATA[<p>今天下午在58上面看到一条消息，说的是190出售双核电脑，立即就心动了。作为一个linux，总是忍不住手痒想重装系统，或者是自定义系统，但是因为现在自己手头上只有一台笔记本，实在是不敢轻举妄动，不然把这电脑弄崩溃了，或者是丢失数据了那就损失惨重了。如果有一台空闲的机器那就好了，我可以随便在那台机器上面装系统，可以随意定制。而且有一台局域网内部的PC当作服务器，拿来当测试机很不错，在这里测试过代码之后再上传到线上vps上去。</p>

<p>说干就干，反正190也不贵，现在出去随便找个饭店吃个稍微好点的饭都不止190.给卖家打了电话先问了一下基本的情况，大致确定了消息的真实性，然后就是出发去验货了。那个卖家在东城区，好远啊，看了一下时间都已经3点半了，赶紧出发。又是转公交又是转地铁，终于到了东四北大街，来到了卖家的家里。太震惊了，卖家竟然是一个50多岁的老头，家里很简陋，胡同里很老的房子，但是里面堆满了电脑主机，估计有2,3百台。我要买的那台电脑正开着呢，装着win7系统，正在通过pptv看视频呢。cpu是amd的，1.9GHZ，ddr2内存1G大，网卡是100M的螃蟹卡，这种网卡对于*unix来说几乎都是免驱动的了，使用的太广泛了。剩下的就没什么说了，反正是打算拿来当服务器的，对于显卡没什么要求。</p>

<p>成交之后就抱着这主机又穿过了大半个北京回到了住的地方，累死我了。</p>

<p>回来之后打算装系统，问了一下群里的几个朋友，他们都说要装系统的话必须要有显示器才行。伤心，我还以为有一键安装系统的脚本呢，看来系统是得下周拿到公司去装了。真搞不懂，如果服务器装机也像普通桌面电脑一样的话，那些大公司的运维该多惨，几百台机器得装。</p>

<p>接下来就是得好好想想服务器装什么系统好了，现在vps上跑的是freebsd10,已经连续运行3个多月了，稳定性还可以。但是我自己桌面装的是archlinux，相对来说arch的用法还是比freebsd要简单得多。说到这里又想到这几天debian多位核心开发者离职，好像就是因为debian8要采用systemd的原因。arch很早就用了systemd来管理系统启动进程，导致现在用arch几乎都是傻瓜式了，开启某个软件，安装某个软件，检测某个进程运行状态，都可以通过systemctl来实现。对于*inux的哲学来说还是一个软件只干一件事，对于这种想把什么事都干掉的软件，freebsd是很抵制的。</p>

<p>真搞不懂到底哪种才是对的。</p>

<p>昨天在公司加班终于把zeze的代码部署到git上了。</p>

<p>之前用的版本管理是svn，但是我不太喜欢svn，因为emacs不支持它。我喜欢git，因为emacs对git的支持很好，通过magit我可以很轻松的看到每个版本之间的改动，可以任意提交代码。其实我也不是很熟悉git，但是得慢慢来学，以后git肯定是会取代svn的。</p>

<p>我把svn里面的代码复制到内网测试机之后，<code>git init</code>了这个目录，然后执行初始化提交，然后在本地执行<code>git clone user@host:/project/ ./project</code>把代码拷到了本地，打算在本地改了之后up到服务器上。但是后来我发现我想多了，git不是svn，用svn的这种思路是行不通的，线上的代码和本地的代码是毫无关系的2个分支，本地改了之后提交执行<code>git push</code>是会报错的。</p>

<p>那么什么才是正确的git方式呢？查看了一下git的文档，发现上面说git有一个版本库，克隆这个版本库就能获得最新的版本。</p>

<ol>
<li>先把代码复制到本地，<code>scp -r online_code local_code</code></li>
<li>把本地代码初始化成一个git仓库，<code>git init</code></li>
<li>把本地代码都加入到git版本中，<code>git add .</code></li>
<li>第一次提交代码，<code>git commit -m 'init commit'</code></li>
<li>把本地仓库推送到远程服务器上，<code>git remote add gituser@gitserver:/local_code.git</code>，在执行这步的时候必须确保git服务器上面已经存在local_code.git这个目录，如果不存在的话就得<code>mkdir local_code.git</code></li>
<li>把本地仓库保存的版本都推送到服务器上，<code>git push origin master</code></li>
<li>ssh上git服务器看看，找到local_code.git这个目录，发现里面的文件竟然和本地代码里面<code>local_code/.git/</code>下的内容一模一样</li>
<li>把仓库里的代码克隆到对外访问的环境，因为我是在本地做的测试，所以代码仓库和web服务器是在同一台机器上的，直接执行<code>git clone local_code.git /srv/http/online_code</code>就把版本库里面记录的代码复制出来放到服务器目录了。</li>
</ol>


<p>之前我直接在服务器上写代码，提交代码的时候真是落后，得通过命令行来提交代码，magit没法判断远程服务器上的代码的版本。现在这样就好了，我可以用magit随时commit,随时push，然后只要到<code>/srv/http/online_code/</code>下面<code>git pull</code>就行了。</p>
]]></content>
  </entry>
  
</feed>
